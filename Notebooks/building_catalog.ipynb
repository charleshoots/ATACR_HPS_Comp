{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "from obspy.core import read, Stream, Trace, AttribDict, UTCDateTime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/COMPS')\n",
    "sys.path.insert(0, '/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/METHODS/ATaCR/ATaCR_Python/OBStools')\n",
    "sys.path.insert(0, '/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/METHODS/ATaCR/ATaCR_Python')\n",
    "import ObsQA\n",
    "import datetime\n",
    "from obspy.clients.fdsn import Client\n",
    "import glob as g\n",
    "import os\n",
    "import argparse\n",
    "import obspy\n",
    "import obstools as obs\n",
    "from obstools.atacr import DayNoise, TFNoise, EventStream, StaNoise, utils\n",
    "import obstools.atacr.plotting as atplot\n",
    "from obstools.scripts import comply_calculate, atacr_clean_spectra, atacr_correct_event, atacr_daily_spectra, atacr_download_data, atacr_download_event, atacr_transfer_functions\n",
    "from stdb.scripts import query_fdsn_stdb\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import fnmatch\n",
    "from comp_tools import *\n",
    "## stations, stations_set = ObsQA.io.getstalist()\n",
    "dirs = ObsQA.io.dir_libraries('/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/METHODS/ATaCR')[1]\n",
    "eventsfolder = dirs['Py_CorrectedTraces']\n",
    "## eventsfolder = '/Users/charlesh/Documents/Codes/ATaCR/ATaCR_Comp/ATaCR_Python/EVENTS'\n",
    "# catalog = pd.read_pickle(eventsfolder + '/event_catalog_updated.pkl')\n",
    "catalog_orig = pd.read_excel('/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/METHODS/ATaCR/ATaCR_Python/utilities/Janiszewski_etal_2023_StationList.xlsx')\n",
    "\n",
    "## catalog = pd.read_pickle(eventsfolder + '/sta_catalog_evrecord_set_goodchans.pkl')\n",
    "# catalog = pd.read_pickle(eventsfolder + '/sta_catalog_evrecord_set_goodchans_updated.pkl')\n",
    "ATaCR_Parent = dirs['Py_DataParentFolder']\n",
    "\n",
    "catalog = pd.read_pickle(eventsfolder + '/sta_catalog_proxima_test.pkl')\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "##########----Combine two catalogs\n",
    "# Can use this with pull_from_catalog(add_stations,catalog_orig) to add new stations to a given catalog\n",
    "##############################################################################################################\n",
    "##############################################################################################################\n",
    "# catalog = pd.read_pickle(eventsfolder + '/sta_catalog_proxima_test.pkl')\n",
    "# catalog_surplus = catalog[catalog.n_events>=20]\n",
    "# catalog = catalog[catalog.n_events<20]\n",
    "# fill_catalog = pd.read_pickle(eventsfolder + '/sta_catalog_proxima_fill.pkl')\n",
    "# addendum = fill_catalog[-4:]\n",
    "\n",
    "# dateformat = '%Y.%j.%H.%M'\n",
    "# for stai,s in enumerate(catalog.iloc):\n",
    "#   fill = fill_catalog.iloc[np.where(fill_catalog.StaName==s.StaName)[0][0]]\n",
    "#   a = [b for b in s.Metadata]\n",
    "#   a.extend([a for a in fill.Metadata])\n",
    "#   Metadata = obspy.Catalog(a)\n",
    "#   Origin = [a.origins[0] for a in Metadata]\n",
    "#   Events = [m.origins[0].time.strftime(dateformat) for m in Metadata]\n",
    "#   Magnitude_mw = [m.magnitudes[0].mag for m in Metadata]\n",
    "#   Depth_KM = [m.origins[0].depth/1000 for m in Metadata]\n",
    "#   n_events = len(Metadata)\n",
    "#   catalog.at[stai,'n_events'] = n_events\n",
    "#   catalog.at[stai,'Magnitude_mw'] = Magnitude_mw\n",
    "#   catalog.at[stai,'Origin'] = Origin\n",
    "#   catalog.at[stai,'Metadata'] = Metadata\n",
    "#   catalog.at[stai,'Events'] = Events\n",
    "#   catalog.at[stai,'Depth_KM'] = Depth_KM\n",
    "#   catalog = catalog.reset_index(drop=True)\n",
    "\n",
    "# updated_catalog = pd.concat([catalog,catalog_surplus,addendum])\n",
    "# updated_catalog = updated_catalog.sort_values(by='Network',ascending=True)\n",
    "# updated_catalog = updated_catalog.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "##########----Get a new catalog of events for the given set of stations, mags, and windows\n",
    "##############################################################################################################\n",
    "##############################################################################################################\n",
    "# catalog = pd.read_pickle(eventsfolder + '/sta_catalog_proxima_test.pkl')\n",
    "# mags = [[7.1,8.0]]\n",
    "# windows = 'sta'\n",
    "# windows = None\n",
    "# hardcap = 25\n",
    "# addendum_catalog = build_event_catalog(catalog,mags=mags,windows=windows,hardcap = hardcap)\n",
    "# addendum_catalog\n",
    "# cat = catalog.copy()\n",
    "# adds = addendum_catalog.copy()\n",
    "# for stai,Station in enumerate(cat.iloc):\n",
    "#   if cat.iloc[stai].Station is not adds.iloc[stai].Station:\n",
    "#     print('Broken Pipe')\n",
    "#     raise SystemExit\n",
    "#     # Exception('')\n",
    "#   for k in ['Magnitude_mw','Origin','Metadata','Events','Depth_KM']:\n",
    "#     tmp = cat.iloc[stai][k]\n",
    "#     adds.iloc[stai][k]\n",
    "#     tmp.extend(adds.iloc[stai][k])\n",
    "#     cat.at[stai,k] = tmp\n",
    "#   cat.at[stai,'n_events'] = len(cat.at[stai,'Events'])\n",
    "#   cat = cat.reset_index(drop=True)\n",
    "# updated_catalog = cat.copy()\n",
    "# updated_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "##########----GIANT plot of deployment coverage for a given catalog\n",
    "##############################################################################################################\n",
    "##############################################################################################################\n",
    "# catalog = new_catalog.copy()\n",
    "# # catalog = pd.read_pickle('/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/METHODS/ATaCR/ATaCR_Python/EVENTS/sta_catalog_proxima.pkl')\n",
    "# catalog = catalog.sort_values(by=['Network','Water_Depth_m'])\n",
    "# D = pd.read_excel('/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/METHODS/ATaCR/ATaCR_Python/utilities/Janiszewski_etal_2023_StationList.xlsx')\n",
    "# D['Station'] = [str(a) for a in D.Station]\n",
    "# D = D.iloc[[np.where(D.Station==a)[0][0] for a in catalog.Station.iloc]]\n",
    "# Dstations = [str(e) for e in D.Station]\n",
    "# DExp = np.unique(['[' + str(n) + '] ' + ' ' + str(x) + ' ' for n,x in zip(D.Network,D.Experiment)])\n",
    "# DStart = [str(e) for e in D.Start]\n",
    "# DEnd = [str(e) for e in D.End]\n",
    "# n = 1\n",
    "# for i,s in enumerate(Dstations):\n",
    "#     s = ' '*(n*(15)) + s + ' '*(np.abs(n-1)*(15))\n",
    "#     n = np.abs(n-1)\n",
    "#     Dstations[i] = s\n",
    "# client = Client()\n",
    "# evts = client.get_events(starttime=np.min(D.Start), endtime=np.max(D.End),minmagnitude=6.0,maxmagnitude=7.0)\n",
    "# evtimes = [d.origins[0].time for d in evts]\n",
    "# days = np.array([np.min(D.Start) + datetime.timedelta(days=i) for i in range((np.max(D.End) - np.min(D.Start) + datetime.timedelta(seconds=1)).days)])\n",
    "# counts = np.zeros(days.shape)\n",
    "# for ev in evtimes:\n",
    "#     counts[np.where(days==datetime.datetime(year=ev.year,day=ev.day,month=ev.month))[0][0]] +=int(1)\n",
    "# from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "# import matplotlib as mpl\n",
    "# from matplotlib.ticker import AutoLocator\n",
    "# import matplotlib.dates as mdates\n",
    "# # from matplotlib import cm\n",
    "# def tmp_time_cdf(s_start,s_end,evtimes):\n",
    "#     e = [evts[i] for i in np.where(np.logical_and((s_end  > np.array(evtimes)),(s_start < np.array(evtimes))))[0]]\n",
    "#     e_times = [k.origins[0].time for k in e]\n",
    "#     e_times = [datetime.datetime(year=e_times[k].year,month=e_times[k].month,day=e_times[k].day,hour=e_times[k].hour,minute=e_times[k].minute) for k in range(len(e_times))]\n",
    "#     to_timestamp = np.vectorize(lambda x: x.timestamp())\n",
    "#     time_stamps = to_timestamp(e_times)\n",
    "#     hist,edges = np.histogram(time_stamps,density=False,bins=len(e_times))\n",
    "#     histc = hist\n",
    "#     # hist = hist / np.sum(hist)\n",
    "#     days = np.array([s_start + datetime.timedelta(days=i) for i in range((s_end - s_start).days+1)])\n",
    "#     prob = scipy.interpolate.interp1d(edges[0:-1], hist,kind='nearest',fill_value=0,bounds_error=False)\n",
    "#     prob = prob(to_timestamp(days))\n",
    "#     edges = [datetime.date.fromtimestamp(j) for j in edges][0:-1]\n",
    "#     days = days[prob>0]\n",
    "#     prob = prob[prob>0]\n",
    "#     return days,prob\n",
    "# def day_counts(s_start,s_end,days,counts,min=0,max=1000):\n",
    "#     s_start = datetime.datetime(year=s_start.year,day=s_start.day,month=s_start.month)\n",
    "#     s_end = datetime.datetime(year=s_end.year,day=s_end.day,month=s_end.month)\n",
    "#     d=days[np.where(np.logical_and(days>s_start,days<s_end))[0]]\n",
    "#     c=counts[np.where(np.logical_and(days>s_start,days<s_end))[0]]\n",
    "#     d = d[c>0]\n",
    "#     c = c[c>0]\n",
    "#     d = d[c>min]\n",
    "#     c = c[c>min]\n",
    "#     d = d[c<max]\n",
    "#     c = c[c<max]\n",
    "#     d = d[np.argsort(c)]\n",
    "#     c = c[np.argsort(c)]\n",
    "#     return d,c\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(45,45),width_ratios=[0.2,1],layout='constrained',squeeze=False,sharey='all')\n",
    "# ax = axes[0][1]\n",
    "# lk = []\n",
    "# yt = [(i*100) for i in range(len(Dstations))]\n",
    "# expyt = [yt[np.max(np.where(D.Network==j))]+1 for j in np.unique(D.Network)]\n",
    "# cyt = []\n",
    "# norm = mpl.colors.Normalize(vmin=1, vmax=int(np.max(counts[counts<np.max(counts)])))\n",
    "# for s in catalog.Station:\n",
    "#     k = (np.where(s ==D.Station)[0])\n",
    "#     if len(k)==0:\n",
    "#         continue\n",
    "#     elif len(k)==1:\n",
    "#         cyt.append(yt[k[0]])\n",
    "# [plt.axhline(y,color='r',linewidth=1.5,ls=':',zorder=-1,alpha=0.75) for y in cyt]\n",
    "# [plt.axhline(j,ls='-',c='w',zorder=-2) for j in expyt]\n",
    "# colors = [(0, .2, .6),(0, 1, 0)]  # R -> G -> B\n",
    "# n = len(np.unique(counts[counts<np.max(counts)]))\n",
    "# cmap = LinearSegmentedColormap.from_list('my_list', colors, N=100).resampled(len(np.unique(counts[counts<np.max(counts)])[1:]))\n",
    "# c = cmap(np.linspace(0,1,3)).tolist()\n",
    "# c.append((1, 0, 0))\n",
    "# cmap = LinearSegmentedColormap.from_list('my_list', c, N=100).resampled(len(np.unique(counts[counts<np.max(counts)])[1:]))\n",
    "# anomaly_bar = np.ceil(np.std(counts[counts>0])*2) + np.ceil(np.mean(counts[counts>0]))\n",
    "# for ii,(s_start,s_end,yy) in enumerate(zip(D.Start,D.End,yt)):\n",
    "#     for min,max in zip([0,6],[6,100]):\n",
    "#         dys,cts = day_counts(s_start,s_end,days,counts,min=min,max=max)\n",
    "#         if len(cts)>0:\n",
    "#             lk.append(np.max(cts))\n",
    "#         else:\n",
    "#             continue\n",
    "#         if np.max(cts)>anomaly_bar:\n",
    "#             plt.scatter(dys,cts*0+yy,c=cts,s=30, marker='s',cmap=cmap,norm=norm,edgecolor='k',linewidth=0.5)\n",
    "#         else:\n",
    "#             plt.scatter(dys,cts*0+yy,c=cts,s=20, marker='s',cmap=cmap,norm=norm,edgecolor='k',linewidth=0.5)\n",
    "# plt.yticks(ticks = yt, labels = Dstations,fontsize=7,fontweight='bold')\n",
    "# ax.xaxis.set_major_locator(AutoLocator())\n",
    "# ax.grid(visible=True,axis='x')\n",
    "# plt.xlim(np.min(D.Start),np.max(D.End))\n",
    "# xx = np.min(plt.gca().get_xlim()) + 50\n",
    "# v = [plt.text(xx,i,j,fontweight='bold',bbox=dict(facecolor='w', alpha=1),fontsize=9) for i,j in zip(expyt,DExp)]\n",
    "# yl = plt.gca().get_ylim()\n",
    "# plt.ylim(np.min(yt),np.max(yt)*1.01)\n",
    "# plt.gca().set_facecolor('dimgray')\n",
    "# plt.tick_params(labelbottom=True, labeltop=True, labelleft=False, labelright=False,bottom=True, top=True, left=False, right=False)\n",
    "# ax.set_xticklabels(labels=ax.get_xticklabels(),fontsize=10,fontweight='bold')\n",
    "# dtFmt = mdates.DateFormatter('%y/%m') # define the formatting\n",
    "# ax.xaxis.set_major_formatter(dtFmt)\n",
    "# ax.xaxis.set_major_locator(mdates.MonthLocator(interval=4))\n",
    "# cb = plt.colorbar(location='top',pad=-0.02,fraction=0.15,aspect=80)\n",
    "# plt.title('OBS Experiments Deployment Coverage\\n Colored by # of m6.0-7.0 events',fontweight='bold',y=1.02,fontsize=14)\n",
    "# plt.clim(vmin=1,vmax=int(np.max(counts[counts<np.max(counts)])))\n",
    "# ax = axes[0][0]\n",
    "# ax.xaxis.set_major_locator(AutoLocator())\n",
    "# x = D['Water Depth (m)']\n",
    "# ax.tick_params(labeltop=True, top=True, labelbottom=True, labelleft=False, labelright=True,bottom=True,left=True, right=True)\n",
    "# ax.barh(yt,x,height=60,color='k')\n",
    "# xlab = [str(int(e)) for e in ax.get_xticks()]\n",
    "# xt = [int(e) for e in ax.get_xticks()]\n",
    "# ax.set_yticks(ticks = yt, labels = Dstations,fontsize=7,fontweight='bold')\n",
    "# ax.set_xticklabels(labels=xlab,fontsize=10,fontweight='bold')\n",
    "# ax.set_xticks(xt)\n",
    "# ax.set_ylim(np.min(yt),np.max(yt)*1.01)\n",
    "# ax.set_xlim(np.min(x),np.max(x)*1.01)\n",
    "# ax.grid(visible=True)\n",
    "# ax.set_xlabel('OBS Depth (m)',fontweight='bold',fontsize=14)\n",
    "# ax.xaxis.set_label_coords(0.5,1.01)\n",
    "# save_tight('/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/COMPS/FigureArchive/_GEN4/DeploymentCoverage.png',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Seismic_Noise_Data_Obspy_ML_NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
