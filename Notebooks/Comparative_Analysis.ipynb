{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###===================================================================================================================================================================\n",
    "# ###===================================================================================================================================================================\n",
    "# ========================================================================================================================================================\n",
    "# ================================================================CODE SNIPPETS===========================================================================\n",
    "# ========================================================================================================================================================\n",
    "# for a in cm._cmap_names_categorical:\n",
    "#     display(cm.__dict__[a].resampled(4))\n",
    "# # ======================================================================================================================================================\n",
    "# # ======================================================================================================================================================\n",
    "# for (Event,Station,Metrics,Comp) in OBS_Generator(catalog,ATaCR_Py_DataFolder['Py_DataParentFolder']):\n",
    "#     display(Event)\n",
    "# for i,(Event,Station,Metrics,Comp) in zip(range(1),OBS_Generator(catalog,ATaCR_Py_DataFolder['Py_DataParentFolder'])):\n",
    "#     print(Event)\n",
    "# # ======================================================================================================================================================\n",
    "# # ======================================================================================================================================================\n",
    "# display(catalog)\n",
    "# print('Compliance band for dataset: ' + str(int(1/fnotch(52))) + '-' + str(int(1/fnotch(5949))) + 's')\n",
    "# print('-----'*10)\n",
    "# print('Water Depth min:  ' + str(catalog.Water_Depth_m.min()))\n",
    "# print('Water Depth max:  ' + str(catalog.Water_Depth_m.max()))\n",
    "# print('-----'*10)\n",
    "# print('Sediment Thickness min:  ' + str(catalog.Sediment_Thickness_m.min()))\n",
    "# print('Sediment Thickness max:  ' + str(catalog.Sediment_Thickness_m.max()))\n",
    "# print('-----'*10)\n",
    "# print('Distance to Plate Boundary min:  ' + str(catalog.Distance_to_Plate_Boundary_km.min()))\n",
    "# print('Distance to Plate Boundary max:  ' + str(catalog.Distance_to_Plate_Boundary_km.max()))\n",
    "# print('-----'*10)\n",
    "# print('Distance from Land min:  ' + str(catalog.Distance_from_Land_km.min()))\n",
    "# print('Distance from Land max:  ' + str(catalog.Distance_from_Land_km.max()))\n",
    "# print('-----'*10)\n",
    "# print('Surface Current min:  ' + str(catalog.Surface_Current_ms.min()))\n",
    "# print('Surface Current max:  ' + str(catalog.Surface_Current_ms.max()))\n",
    "# print('-----'*10)\n",
    "# print('# Events mean:  ' + str(int(catalog.n_events.mean()) - int(catalog.n_events.std())))\n",
    "# print('-----'*10)\n",
    "# print('Events:  ' + str(len(np.unique(events))))\n",
    "# print('Depth Km min:  ' + str(np.min(catalog.Depth_KM.min())))\n",
    "# print('Depth Km max:  ' + str(np.max(catalog.Depth_KM.max())))\n",
    "# print('-----'*10)\n",
    "# print('Start min:  ' + str(catalog.Start.min()))\n",
    "# print('Start max:  ' + str(catalog.End.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================================\n",
    "# ============================================ IMPORTS ==============================================\n",
    "# ===================================================================================================\n",
    "import sys\n",
    "from pathlib import Path\n",
    "project_path = Path('/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/ATACR_HPS_Comp')\n",
    "# sys.path.insert(1,'/Users/charlesh/Documents/Codes/')\n",
    "# sys.path.insert(0, '/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/COMPS')\n",
    "sys.path.append(str(project_path / 'Packages'))\n",
    "sys.path.insert(0, str(project_path / 'Packages' / 'ATaCR'))\n",
    "sys.path.insert(0, str(project_path / 'Packages' / 'CompCode'))\n",
    "sys.path.insert(0, str(project_path / 'Packages' / 'NoiseCut'))\n",
    "sys.path.insert(0, str(project_path / 'Packages' / 'ATaCR'/ 'OBStools'))\n",
    "\n",
    "import requests \n",
    "from PIL import Image \n",
    "import math\n",
    "import scipy\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import shutil\n",
    "from scipy.signal import stft, detrend\n",
    "os.environ['PYDEVD_WARN_SLOW_RESOLVE_TIMEOUT'] = '2'\n",
    "from obspy import Trace\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib\n",
    "import sys\n",
    "import obspy\n",
    "from obspy.signal import PPSD\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "import pickle as pkl\n",
    "import glob as g\n",
    "from obspy.clients.fdsn import Client\n",
    "import datetime\n",
    "import re\n",
    "import math\n",
    "from numpy import linalg as eigen\n",
    "# import noisecut\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm2\n",
    "from scipy.stats import norm\n",
    "import scipy.stats as stats\n",
    "from scipy import fft\n",
    "# import ntk\n",
    "# from cmcrameri import cm\n",
    "\n",
    "from scipy.interpolate import RBFInterpolator, InterpolatedUnivariateSpline #<----Experimental\n",
    "\n",
    "import ObsQA as OBS\n",
    "# from ObsQA.classes import OBSMetrics as OBSM\n",
    "# from ObsQA.plots import qtp\n",
    "from ObsQA import *\n",
    "# OBSM = OBSMetrics\n",
    "import obstools as obs\n",
    "import cmath\n",
    "from comp_tools import *\n",
    "from scipy.signal import csd as _csd\n",
    "import obspy.imaging.cm as cm\n",
    "from ObsQA.TOOLS.io import *\n",
    "from obspy.geodetics.base import locations2degrees\n",
    "from obspy.geodetics.base import degrees2kilometers\n",
    "sys.path.insert(0, '/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/COMPS')\n",
    "import ObsQA as OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# d = []\n",
    "# e = []\n",
    "# for evi,ev in enumerate(evaudit[evaudit.nsta>9].iloc):\n",
    "#     for s in ev.Stations:\n",
    "#         ella = [ev.ev_lla,ev.ev_lon]\n",
    "#         slla = [catalog[catalog.Station==s].iloc[0].Latitude,catalog[catalog.Station==s].iloc[0].Longitude]\n",
    "#         dist = int(degrees2kilometers(locations2degrees(ella[0],ella[1],slla[0],slla[1])))\n",
    "#         d.append(dist)\n",
    "#         if dist<30:\n",
    "#             e.append(evi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------------------------\n",
    "# ============================================ FOLDERS ===========================================\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "project_path = Path('/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/ATACR_HPS_Comp')\n",
    "ATaCR_DataFolder = str(project_path / '_DataArchive' / 'ATaCR_Data')\n",
    "HPS_DataFolder =str(project_path / '_DataArchive' / 'HPS_Data')\n",
    "NoiseFolder = '/Users/charlesh/Documents/Codes/OBS_Methods/NOISE'\n",
    "plotfolder = str(project_path / '_FigureArchive' / '_GEN5')\n",
    "ATaCR_Py_DataFolder = OBS.TOOLS.io.dir_libraries(ATaCR_DataFolder)[1]\n",
    "dirs = ATaCR_Py_DataFolder\n",
    "datafolder = ATaCR_Py_DataFolder['Py_DataParentFolder']\n",
    "eventsfolder = ATaCR_Py_DataFolder['Py_CorrectedTraces']\n",
    "Folder = Path(plotfolder) / 'MeetingFigs'\n",
    "Folder.mkdir(exist_ok=True)\n",
    "# CompFolder = NoiseFolder + '/COMPS/ATaCR_NC'\n",
    "# MethodsFolder = NoiseFolder + '/METHODS'\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# ============================================ LOAD DATA ===========================================\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "catalog = pd.read_pickle(eventsfolder + '/event_catalog_updated.pkl')\n",
    "Station,evi = catalog.iloc[22],3\n",
    "Event = Station.Events[evi]\n",
    "# catalog = pd.read_pickle('/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/METHODS/ATaCR/ATaCR_Python/Metrics/EVENTS/EventMetrics_using_STA_avgTFs.pkl')\n",
    "# catalog = pd.read_pickle('/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/METHODS/ATaCR/ATaCR_Python/EVENTS/event_catalog_updated.pkl')\n",
    "# catalog = pd.read_pickle(eventsfolder + '/sta_catalog_evrecord_set_goodchans_updated.pkl')\n",
    "# catalog = catalog.drop(index=29)\n",
    "catalog = pd.read_pickle(eventsfolder + '/sta_catalog_proxima_test.pkl')\n",
    "# evaudit = ObsQA.io.audit_events(eventsfolder)\n",
    "evaudit = pd.read_pickle(Path(eventsfolder) / 'event_record_audit.pkl')\n",
    "\n",
    "def smooth(d,k=10):\n",
    "        return np.convolve(d, np.ones(k) / k, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Station</th>\n",
       "      <td>M08A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network</th>\n",
       "      <td>7D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>44.118698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>-124.895302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment</th>\n",
       "      <td>CASCADIA INITIATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instrument_Design</th>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seismometer</th>\n",
       "      <td>Trillium Compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Environment</th>\n",
       "      <td>North Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pressure_Gauge</th>\n",
       "      <td>DPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water_Depth_m</th>\n",
       "      <td>126.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distance_from_Land_km</th>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distance_to_Plate_Boundary_km</th>\n",
       "      <td>37.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sediment_Thickness_m</th>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface_Current_ms</th>\n",
       "      <td>0.033541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crustal_Age_Myr</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Start</th>\n",
       "      <td>2011-10-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>End</th>\n",
       "      <td>2012-07-18 23:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deployment_Length_days</th>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good_Channels</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_events</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnitude_mw</th>\n",
       "      <td>[6.0, 7.0, 7.0, 6.0, 6.3, 6.5, 6.6, 6.3, 6.3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Origin</th>\n",
       "      <td>[2012-07-08T11:33:05.290000Z, 2011-10-28T18:54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metadata</th>\n",
       "      <td>[[[resource_id, event_type, event_type_certain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Averaging</th>\n",
       "      <td>Averaging    [sta, sta, sta, sta, sta, sta, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Events</th>\n",
       "      <td>[2012.190.11.33, 2011.301.18.54, 2012.074.09.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Files</th>\n",
       "      <td>[7D.M08A.2012.190.11.33.sta.pkl, 7D.M08A.2011....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Depth_KM</th>\n",
       "      <td>[37.7, 29.0, 19.2, 16.0, 69.2, 65.4, 117.7, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network_Experiment</th>\n",
       "      <td>[7D] CASCADIA INITIATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StaName</th>\n",
       "      <td>7D.M08A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              22\n",
       "Station                                                                     M08A\n",
       "Network                                                                       7D\n",
       "Latitude                                                               44.118698\n",
       "Longitude                                                            -124.895302\n",
       "Experiment                                                   CASCADIA INITIATIVE\n",
       "Instrument_Design                                                             AB\n",
       "Seismometer                                                     Trillium Compact\n",
       "Environment                                                        North Pacific\n",
       "Pressure_Gauge                                                               DPG\n",
       "Water_Depth_m                                                              126.4\n",
       "Distance_from_Land_km                                                       42.0\n",
       "Distance_to_Plate_Boundary_km                                             37.608\n",
       "Sediment_Thickness_m                                                       320.0\n",
       "Surface_Current_ms                                                      0.033541\n",
       "Crustal_Age_Myr                                                              NaN\n",
       "Start                                                        2011-10-20 00:00:00\n",
       "End                                                          2012-07-18 23:59:59\n",
       "Deployment_Length_days                                                     273.0\n",
       "Good_Channels                                                               True\n",
       "n_events                                                                      30\n",
       "Magnitude_mw                   [6.0, 7.0, 7.0, 6.0, 6.3, 6.5, 6.6, 6.3, 6.3, ...\n",
       "Origin                         [2012-07-08T11:33:05.290000Z, 2011-10-28T18:54...\n",
       "Metadata                       [[[resource_id, event_type, event_type_certain...\n",
       "Averaging                      Averaging    [sta, sta, sta, sta, sta, sta, st...\n",
       "Events                         [2012.190.11.33, 2011.301.18.54, 2012.074.09.0...\n",
       "Files                          [7D.M08A.2012.190.11.33.sta.pkl, 7D.M08A.2011....\n",
       "Depth_KM                       [37.7, 29.0, 19.2, 16.0, 69.2, 65.4, 117.7, 11...\n",
       "Network_Experiment                                      [7D] CASCADIA INITIATIVE\n",
       "StaName                                                                  7D.M08A"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog[catalog.Station=='M08A'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "_ = [events.extend(c) for c in catalog.Events]\n",
    "len(np.unique(events))\n",
    "\n",
    "\n",
    "print('Networks:  ' + str(len(catalog.Network.unique())))\n",
    "print('             |:| ' + str(catalog.Experiment.unique()))\n",
    "print('-----'*10)\n",
    "print('Seismometers :  ' + str(len(catalog.Seismometer.unique())))\n",
    "print('             |:| ' + str(catalog.Seismometer.unique()))\n",
    "print('-----'*10)\n",
    "print('Instrument Designs:  ' + str(len(catalog.Instrument_Design.unique())))\n",
    "print( '             |:| ' + str(catalog.Instrument_Design.unique()))\n",
    "print('-----'*10)\n",
    "print('DPG Pressure Gauges:  ' + str(np.sum(catalog.Pressure_Gauge=='DPG')))\n",
    "print('APG Pressure Gauges:  ' + str(np.sum(catalog.Pressure_Gauge=='APG')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ppsd(self,verbose=False,ppsd_length=None,db_bins=(-200, -50, 1.0),overlap=0.5,skip_on_gaps=True):\n",
    "    self.ppsd = dict()\n",
    "    for key in list(self.traces.keys()):\n",
    "        st = Stream(self.traces[key])\n",
    "        if not ppsd_length:\n",
    "            fs = 1/st[0].stats.delta\n",
    "            # ppsd_length = int(round(2**np.ceil(np.log2(120*(fs))))) / st[0].stats.delta\n",
    "            ppsd_length = int(round(2**np.ceil(np.log2(26*(fs))))) / st[0].stats.delta\n",
    "        metadata = {'gain':1., 'sensitivity': 1., 'poles':[1-1j], 'zeros': [1-1j]}\n",
    "        stats = st[0].stats\n",
    "        ppsd_prefs = AttribDict()\n",
    "        ppsd_prefs.skip_on_gaps=skip_on_gaps\n",
    "        ppsd_prefs.ppsd_length=ppsd_length\n",
    "        ppsd_prefs.db_bins=db_bins\n",
    "        ppsd_prefs.overlap=overlap\n",
    "        ppsd = PPSD(stats = stats,metadata = metadata,**ppsd_prefs)\n",
    "        success = ppsd.add(st,verbose=verbose)\n",
    "        if success:\n",
    "            print(key + ' | Number of psd segments:', len(ppsd.times_processed))\n",
    "        else:\n",
    "            print('PPSD Failed')\n",
    "        self.ppsd[k] = ppsd\n",
    "    return self\n",
    "def ppsd_plot(comp,\n",
    "    # --------Post plot tweaks\n",
    "    figsize = [15,8],\n",
    "    eq_lines = ['gray',0.9,'-'],\n",
    "    suptitle = None,\n",
    "    average_line = ['k',2,'-.'],\n",
    "    earthquakes = (5,7,3000),\n",
    "    period = [1,200],\n",
    "    show_coverage = False,\n",
    "    # cmap = obspy.imaging.cm.viridis\n",
    "    cmap = obspy.imaging.cm.pqlx,\n",
    "    xaxis_frequency = False,\n",
    "    append_title = None,\n",
    "    # --------\n",
    "    ):\n",
    "    ppsd = self.ppsd[comp]\n",
    "    if earthquakes==True:\n",
    "        earthquakes = (5,7,3000)\n",
    "    plot_prefs = AttribDict()\n",
    "    if average_line:\n",
    "        plot_prefs.show_mean = True\n",
    "    else:\n",
    "        plot_prefs.show_mean = False\n",
    "    plot_prefs.show_coverage=show_coverage\n",
    "    plot_prefs.show_earthquakes=earthquakes\n",
    "    plot_prefs.period_lim=period\n",
    "    plot_prefs.cmap=cmap\n",
    "    plot_prefs.show=False\n",
    "    plot_prefs.xaxis_frequency=xaxis_frequency\n",
    "    # average_line = None\n",
    "    hevent = ppsd.plot(**plot_prefs)\n",
    "    _ = hevent.set_figwidth(figsize[0])\n",
    "    _ = hevent.set_figheight(figsize[1])\n",
    "    hevent.suptitle(suptitle)\n",
    "    # Assuming 'hevent' is your figure object\n",
    "    fig = hevent\n",
    "    # Access the first axes in the figure (adjust the index if needed)\n",
    "    ax = fig.axes[0]\n",
    "    if earthquakes:\n",
    "        texts = [text for text in ax.get_children() if isinstance(text,plt.Text)][:-3]\n",
    "        [t.set_position([t.get_position()[0]*(2.1+0.0*ti),t.get_position()[1]*(0.911-0.013*ti)]) for ti,t in enumerate(texts)]\n",
    "        [t.set_text(t.get_text().replace('\\n',' - ')) for t in texts]\n",
    "        [t.set_rotation(20) for t in texts]\n",
    "    # Identify line objects\n",
    "    lines = [line for line in ax.get_children() if isinstance(line, plt.Line2D)]\n",
    "    stack = 0\n",
    "    if average_line:\n",
    "        # averaging line\n",
    "        lines[0].set_color(average_line[0])  # Change color of the first line to red\n",
    "        lines[0].set_linewidth(average_line[1])\n",
    "        lines[0].set_linestyle(average_line[2])\n",
    "    if plot_prefs.show_mean:\n",
    "        stack +=1\n",
    "    # noise model lines\n",
    "    lines[stack].set_color('red')  # Change color of the first line to red\n",
    "    lines[stack+1].set_color('red')  # Change color of the second line to blue\n",
    "    stack+=2\n",
    "    if plot_prefs.show_earthquakes:\n",
    "        _ = [l.set_color(eq_lines[0]) for l in lines[stack:]]\n",
    "        _ = [l.set_linewidth(eq_lines[1]) for l in lines[stack:]]\n",
    "        _ = [l.set_linestyle(eq_lines[2]) for l in lines[stack:]]\n",
    "\n",
    "    N = int(len(ppsd.times_processed))\n",
    "    NS = int(UTCDateTime(ppsd.times_processed[2]) - UTCDateTime(ppsd.times_processed[0]))\n",
    "\n",
    "    ttl = fig.axes[0].get_title().replace('  ',' | ')\n",
    "    ttl = ttl.replace('(','').replace(')','')\n",
    "    ttl = ttl.replace('{N}/{N}'.format(N=N),str(N))\n",
    "    ttl = ttl.replace('segments', '({NS}s) segments'.format(NS=NS))\n",
    "\n",
    "    if append_title:\n",
    "        ttl = ttl + '\\n' + append_title\n",
    "    fig.axes[0].set_title(ttl)\n",
    "    fig.canvas.draw()\n",
    "    plt.close('all')\n",
    "    # Show the updated figure (if not already displayed)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat = catalog.copy()\n",
    "#___________________________________________________\n",
    "#___These stations will not return pressure data____\n",
    "# problem_stations = [11, 12, 13, 14, 15, 16, 17, 21, 22, 23, 28, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75,\n",
    "#  76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
    "# cat = cat.iloc[problem_stations]\n",
    "\n",
    "# mustang_folder = Path('/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/COMPS/FigureArchive/_GEN5/EventRecords/QualityMetrics/Mustang-NoiseSpec')\n",
    "# db = None\n",
    "# quality = 'D'\n",
    "# channel = 'Z'\n",
    "# problem_stations = mustang_noise_spec_reports(cat=cat,mustang_folder=mustang_folder,channel=channel,db=db,quality=quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hps_output = Path('/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/METHODS/NoiseCut/Data/Output')\n",
    "# evaudit = pd.read_pickle(Path(eventsfolder) / 'event_record_audit.pkl')\n",
    "# evaudit = evaudit[evaudit.nsta<10]\n",
    "# # evaudit = evaudit.iloc[119:]\n",
    "# raws = ['RawZ','Raw1','Raw2','RawP']\n",
    "# posts = ['PostHPS','PostHPS_H1','PostHPS_H2']\n",
    "# for evi,ev in enumerate(evaudit.iloc()):\n",
    "#   event = ev.Event\n",
    "#   sta = ev.Stations\n",
    "#   net = ev.Networks\n",
    "#   if UTCDateTime.strptime(event,format='%Y.%j.%H.%M').hour >= 22:\n",
    "#     continue\n",
    "\n",
    "#   for i,(n,s) in enumerate(zip(net,sta)):\n",
    "#     (hps_output / f'{n}.{s}').mkdir(parents=True,exist_ok=True)\n",
    "#     output = dict()\n",
    "#     print(f'{evi+1}/{len(evaudit)} | {i+1}/{len(net)} : {n}.{s}.{event}')\n",
    "#     Metrics,Comp = get_metrics_comp(n,s,datafolder,event,return_hps=True,return_atacr=False)\n",
    "#     if len(Comp)==0:\n",
    "#       continue\n",
    "#     Raw = Stream()\n",
    "#     HPS = Stream()\n",
    "#     for e in raws:\n",
    "#       Raw+=Comp[e].copy()\n",
    "#     for e in posts:\n",
    "#       HPS+=Comp[e].copy()\n",
    "#     output['Raw'] = [Raw.copy()]\n",
    "#     output['HPS'] = [HPS.copy()]\n",
    "#     output = pd.DataFrame(output)\n",
    "#     file = f'{n}.{s}.{event}.pkl'\n",
    "#     output.to_pickle(hps_output / f'{n}.{s}' / file)\n",
    "#     del Raw,HPS,Comp,Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NoiseColors = [mcolors.to_hex(m) for m in [cm.__dict__[e].resampled(30).resampled(6).colors for e in ['devon_categorical']][0]]\n",
    "# [display(c) for c in [cm.__dict__[e].resampled(70).resampled(5) for e in ['nuuk_categorical','devon_categorical','hawaii_categorical','imola_categorical','lapaz_categorical']]]\n",
    "# np.array([[mcolors.to_hex(c) for c in r] for r in [cm.__dict__[e].resampled(70).resampled(5).colors for e in ['nuuk_categorical','devon_categorical','hawaii_categorical','imola_categorical','lapaz_categorical']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ____________________________________________________________________________________________\n",
    "# ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "# |||||||||||||||||||||||||||||||||||||||||||||||||BEGIN PLOT CODES|||||||||||||||||||||||||||\n",
    "# ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "# ____________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fractional_different(r,A,B):\n",
    "    a_f,a_coh = A.Coherence(r)\n",
    "    b_f,b_coh = B.Coherence(r)\n",
    "    b_coh = interpolate.interp1d(b_f,b_coh)(a_f)\n",
    "    frac = a_coh / b_coh\n",
    "    return a_f,frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datafolder = dirs['Py_DataParentFolder']\n",
    "# nsta_bar = 20\n",
    "# # evaudit = ObsQA.io.audit_events(eventsfolder)\n",
    "# evaudit = pd.read_pickle(Path(eventsfolder) / 'event_record_audit.pkl')\n",
    "# evaudit = evaudit[evaudit.nsta>=nsta_bar]\n",
    "# # evaudit = evaudit.iloc[100:]\n",
    "# # evsilike = ['2010.247.08.52','2013.143.17.19']\n",
    "# # evsilike = ['2010.247.08.52']\n",
    "# # evsilike = ['2011.242.06.57','2010.246.16.35','2011.191.00.57','2011.236.17.46','2010.163.19.26','2010.096.22.15']\n",
    "# # evsilike = ['2010.073.08.08','2010.216.07.15'] # '2010.151.19.51','2010.204.22.51'\n",
    "\n",
    "# # evsi = [np.where(evaudit.Event==d)[0][0] for d in evsilike]\n",
    "# # evaudit = evaudit.iloc[evsi]\n",
    "# # evaudit = evaudit.iloc[2:]\n",
    "# # evaudit = evaudit[evaudit.MW>=7.1]\n",
    "# # display(evaudit)\n",
    "# # folder = 'grouped_bands'\n",
    "# folder = 'separated_bands'\n",
    "# alumni_poster = Path('/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/COMPS/FigureArchive/_GEN5/EventRecords/AlumniPoster/Events')\n",
    "# ysep_scl = 1.3\n",
    "# figsize = (14,13)\n",
    "# bands = [(1/10,1),(1/30,1/10),(1/100,1/30)]\n",
    "# trim = (10,7200)\n",
    "# tapers = [3]\n",
    "# # methods = ['PostATACR','PostHPS']\n",
    "# methods = ['PostATACR']\n",
    "# # methods = ['PostHPS']\n",
    "# channels = ['Z','1','2']\n",
    "# for correction_method in methods:\n",
    "#   current_method = correction_method.replace('Post','')\n",
    "#   coh_comp = correction_method.replace('PostHPS','HPS').replace('PostATACR','ATaCR')\n",
    "#   if correction_method=='PostHPS':\n",
    "#     return_hps = True\n",
    "#   else:\n",
    "#     return_hps = False\n",
    "#   if return_hps:\n",
    "#     return_atacr = False\n",
    "#   else:\n",
    "#     return_atacr = True\n",
    "#   for taper_mode in tapers:\n",
    "#     OutFolder = Path(plotfolder)\n",
    "#     SubFolders = Path('EventRecords') / ('Taper_' + str(taper_mode)) / correction_method / folder\n",
    "#     OutFolder = OutFolder / SubFolders\n",
    "#     # OutFolder = alumni_poster\n",
    "#     OutFolder.mkdir(parents=True,exist_ok=True)\n",
    "#     plt.figure(figsize=(15,5))\n",
    "#     for evi,ev in enumerate(evaudit.iloc):\n",
    "#         print('=='*40)\n",
    "#         mirror_test = mirror_audit(ev.to_frame().T,datafolder=datafolder)[0]\n",
    "#         mirror_test = np.array(mirror_test[0]) & np.array(mirror_test[1])\n",
    "#         mirror_test = np.where(mirror_test)[0]\n",
    "#         if len(mirror_test)==0:\n",
    "#           print('|| No data mirrors between sets')\n",
    "#           continue\n",
    "#         else:\n",
    "#           print('|| >>> DATASETS MIRROR POPULATION: ' + str(len(mirror_test)))\n",
    "#         if len(mirror_test)<nsta_bar:\n",
    "#           print('Insufficient mirrored data (min:' + str(nsta_bar) + ')')\n",
    "#           continue\n",
    "#         event = ev.Event\n",
    "#         stations = ev.Stations\n",
    "#         networks = ev.Networks.tolist()\n",
    "#         networks = [networks[i] for i in mirror_test]\n",
    "#         stations = [stations[i] for i in mirror_test]\n",
    "#         evdepth = ev.depth\n",
    "#         post_record = Stream()\n",
    "#         pre_record = Stream()\n",
    "#         print('|| [' + str(evi) + '/' + str(len(evaudit)) + '] ' + event + ' | ')\n",
    "#         print('||---Begin load')\n",
    "#         # plt.figure(figsize=(15,5))\n",
    "#         for i,(net,sta) in enumerate(zip(networks,stations)):\n",
    "#             # if ev.Event=='2010.151.19.51':\n",
    "#             #     if sta=='C08W':\n",
    "#             #         _,_= stations.pop(i),networks.pop(i)\n",
    "#             #         continue\n",
    "#             #     if sta=='S01W':\n",
    "#             #         _,_ = stations.pop(i),networks.pop(i)\n",
    "#             #         continue\n",
    "#             Metrics,Comp = get_metrics_comp(net,sta,MethodsFolder,event,return_hps=return_hps,return_atacr=return_atacr,events_folder='EVENTS_Taper_' + str(taper_mode))\n",
    "\n",
    "#             fq,frac = metric_fractional_different('ZP',Metrics['ATaCR'],Metrics['ATaCR'].Noise)\n",
    "#             if np.sum(frac>=1)>(0.95*len(frac)):\n",
    "#               #  Metrics,Comp = get_metrics_comp(net,sta,MethodsFolder,event,return_hps=return_hps,return_atacr=return_atacr,events_folder='EVENTS_Taper_' + str(taper_mode))\n",
    "#                continue\n",
    "#             s = 2\n",
    "#             plt.scatter(fq[frac>=1],frac[frac>=1],c='b',s=s,marker='.')\n",
    "#             plt.scatter(fq[frac<1],frac[frac<1],c='r',s=s,marker='.')\n",
    "#             plt.axhline(1,linestyle=':',linewidth=0.5,c='k')\n",
    "#             # plt.xlim([fq.min(),fq.max()])\n",
    "#             # plt.ylim([frac.min(),frac.max()])\n",
    "#             if len(Metrics)==0:\n",
    "#                 _ = stations.pop(i)\n",
    "#                 _ = networks.pop(i)\n",
    "#                 continue\n",
    "#         plt.yscale('log')\n",
    "#         plt.xscale('log')\n",
    "#         plt.xlim([fq.min(),fq.max()])\n",
    "#         plt.ylim([frac.min(),frac.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "# |||| 1x3 . SEPARATED BANDS . EVENT RECORDS . PLOT CODE |||||\n",
    "# ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "datafolder = dirs['Py_DataParentFolder']\n",
    "nsta_bar = 10\n",
    "evaudit_focus = evaudit.copy()\n",
    "evaudit_focus = evaudit_focus[evaudit_focus.nsta>=nsta_bar].copy()\n",
    "# evaudit_focus = evaudit_focus.iloc[100:]\n",
    "# evsilike = ['2010.247.08.52','2013.143.17.19']\n",
    "# evsilike = ['2011.242.06.57','2010.246.16.35','2011.191.00.57','2011.236.17.46','2010.163.19.26','2010.096.22.15']\n",
    "# evsilike = ['2010.073.08.08','2010.216.07.15'] # '2010.151.19.51','2010.204.22.51'\n",
    "# evsi = [np.where(evaudit_focus.Event==d)[0][0] for d in evsilike]\n",
    "# evaudit_focus = evaudit_focus.iloc[evsi]\n",
    "# evaudit_focus = evaudit_focus.iloc[2:]\n",
    "# evaudit_focus = evaudit_focus[evaudit_focus.MW>=7.1]\n",
    "# display(evaudit_focus)\n",
    "# folder = 'grouped_bands'\n",
    "folder = 'separated_bands'\n",
    "ysep_scl = 1.3\n",
    "figsize = (14,13)\n",
    "bands = [(1/10,1),(1/30,1/10),(1/100,1/30)]\n",
    "trim = (10,7200)\n",
    "# methods = ['PostATACR','PostHPS']\n",
    "methods = ['PostATACR']\n",
    "# methods = ['PostHPS','PostATACR']\n",
    "channels = ['Z','1','2']\n",
    "for correction_method in methods:\n",
    "  current_method = correction_method\n",
    "  coh_comp = correction_method.replace('PostHPS','HPS').replace('PostATACR','ATaCR')\n",
    "  if correction_method=='PostHPS':\n",
    "    return_hps = True\n",
    "  else:\n",
    "    return_hps = False\n",
    "  if return_hps:\n",
    "    return_atacr = False\n",
    "  else:\n",
    "    return_atacr = True\n",
    "  # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "  OutFolder = Path(plotfolder)\n",
    "  SubFolders = Path('EventRecords') / correction_method / folder\n",
    "  OutFolder = OutFolder / SubFolders\n",
    "  OutFolder.mkdir(parents=True,exist_ok=True)\n",
    "  for evi,ev in enumerate(evaudit_focus.iloc):\n",
    "      print('=='*40)\n",
    "      mirror_test = mirror_audit(ev.to_frame().T,datafolder=datafolder)[0]\n",
    "      mirror_test = np.array(mirror_test[0]) & np.array(mirror_test[1])\n",
    "      mirror_test = np.where(mirror_test)[0]\n",
    "      if len(mirror_test)==0:\n",
    "        print('|| No data mirrors between sets')\n",
    "        continue\n",
    "      else:\n",
    "        print('|| >>> DATASETS MIRROR POPULATION: ' + str(len(mirror_test)))\n",
    "      if len(mirror_test)<nsta_bar:\n",
    "        print('Insufficient mirrored data (min:' + str(nsta_bar) + ')')\n",
    "        continue\n",
    "      event = ev.Event\n",
    "      stations = ev.Stations\n",
    "      networks = ev.Networks.tolist()\n",
    "      networks = [networks[i] for i in mirror_test]\n",
    "      stations = [stations[i] for i in mirror_test]\n",
    "      evdepth = ev.depth\n",
    "      post_record = Stream()\n",
    "      pre_record = Stream()\n",
    "      print('|| [' + str(evi) + '/' + str(len(evaudit_focus)) + '] ' + event + ' | ')\n",
    "      print('||---Begin load')\n",
    "      for i,(net,sta) in enumerate(zip(networks,stations)):\n",
    "        if ev.Event=='2010.151.19.51':\n",
    "          if sta=='C08W':\n",
    "            _ = stations.pop(i)\n",
    "            _ = networks.pop(i)\n",
    "            continue\n",
    "          if sta=='S01W':\n",
    "            _ = stations.pop(i)\n",
    "            _ = networks.pop(i)\n",
    "            continue\n",
    "        # try:\n",
    "        Metrics,Comp = get_metrics_comp(net,sta,MethodsFolder,event,return_hps=return_hps,return_atacr=return_atacr,events_folder='EVENTS')\n",
    "        if len(Metrics)==0:\n",
    "            _ = stations.pop(i)\n",
    "            _ = networks.pop(i)\n",
    "            continue\n",
    "        # except:\n",
    "        #   _ = stations.pop(i)\n",
    "        #   _ = networks.pop(i)\n",
    "        #   continue\n",
    "        post_record += Comp[current_method].copy()\n",
    "        pre_record += Comp['RawZ'].copy()\n",
    "        del Metrics\n",
    "        del Comp\n",
    "        if len(post_record)==0:\n",
    "          continue\n",
    "      print('||---Load complete')\n",
    "      phases = ('P','S','SKS','PKiKP','SKiKS','SKSSKS',)\n",
    "      # phases = ('P','S',)\n",
    "      # phases=('ttall',)\n",
    "      evstream = post_record.copy()\n",
    "      evstream_back = pre_record.copy()\n",
    "      facecolor=('b','r')\n",
    "      title = event\n",
    "      sortindex = None\n",
    "      normscale = 0.7\n",
    "      residual_fraction = 0.5\n",
    "      for chan in channels:\n",
    "        pre_record_chan = pre_record.select(channel='*'+chan).copy()\n",
    "        post_record_chan = post_record.select(channel='*'+chan).copy()\n",
    "        for bandi,(band,s) in enumerate(zip(bands,[[1,1],[1,1],[1,1]])):\n",
    "          band_sec = np.sort([1/b for b in band])\n",
    "          print('|| Plotting band: ' + str(band_sec[0]) + ' to ' + str(band_sec[-1]) + 's' + ' | channel:H' + chan)\n",
    "          fig, axes = plt.subplots(nrows=1, ncols=2,figsize=figsize,layout='constrained',squeeze=False,sharey='all',sharex='all')\n",
    "          # fig, axes = plt.subplots(nrows=1, ncols=3,figsize=figsize,layout='constrained',squeeze=False,sharey='all',sharex='all')\n",
    "          # norms='postset'\n",
    "          norms = 'trace'\n",
    "          # norms = 'col'\n",
    "          # norms = np.array([[abs(c.data).max() for c in s] for s in [pre_record,post_record]]).T.max(axis=1).tolist() #global max norm\n",
    "          # norms = np.array([[abs(c.data).max() for c in s] for s in [pre_record]]).T.max(axis=1).tolist() #pre max norm\n",
    "          # norms = np.array([[abs(c.data).max() for c in s] for s in [post_record]]).T.max(axis=1).tolist() #post max norm. >This works well at >m6.5\n",
    "          for record_i,evstream in enumerate([pre_record_chan,post_record_chan]):\n",
    "            # File = 'm' + str(ev.MW) + '_z' + str(ev.depth) + 'km' + '_' + event + '_' + str(band_sec[0]) + 'to' + str(band_sec[-1]) + 's_' + correction_method.replace('Post','') + '_T'\n",
    "            File = 'm' + str(ev.MW) + '_z' + str(ev.depth) + 'km' + '_' + event + '_' + str(band_sec[0]) + 'to' + str(band_sec[-1]) + 's_' + correction_method.replace('Post','')\n",
    "            fig_title = 'm' + str(ev.MW) + '_z' + str(ev.depth) + 'km' + '_' + '-'.join(event.split('.')[:2]) + ' ' + ':'.join(event.split('.')[2:]) + '_' + str(band_sec[0]) + 'to' + str(band_sec[-1]) + 's_Corrected using ' + correction_method.replace('Post','')\n",
    "            ax = axes[0,record_i]\n",
    "            # linewidth = [0.05,0.05,0.05][bandi]\n",
    "            linewidth = [0.2,0.2,0.2][bandi]\n",
    "            ax_title = ['{} Pre-Correction | Channel:{} \\n '.format(current_method,chan),'{} Post-Correction | Channel:{} \\n '.format(current_method,chan)][record_i]\n",
    "            title = File.replace('_',' | ').replace('z','z: ').replace('m','mag: m')\n",
    "            # ---------------\n",
    "            # More reasonable black and white plots:\n",
    "            ax = event_record_plot(evstream=evstream,evstream_back=None,norm=norms,scales=s,linewidth=linewidth,figsize=figsize,band=band,trim=trim,facecolor=facecolor,evdepth=evdepth,phases=phases,title=title,sortindex = sortindex,ax=ax,normscale=normscale,residual_fraction=residual_fraction)\n",
    "            # Use this for those ugly fill mode plots:\n",
    "            # ax = event_record_plot(evstream=evstream,evstream_back=None,norm=norm,scales=s,linewidth=linewidth,figsize=figsize,band=band,trim=trim,facecolor=facecolor,evdepth=evdepth,phases=phases,title=title,sortindex = sortindex,ax=ax,normscale=normscale,residual_fraction=residual_fraction)\n",
    "            # ---------------\n",
    "\n",
    "            ax.set_title(ax_title,fontweight='bold')          \n",
    "# --------------------------------------------- Switch between grouped-band and separated bands plots\n",
    "          # ##### Separated bands\n",
    "          save_format = 'png'\n",
    "          fig.suptitle(fig_title.replace('_',' | ').replace('to',' to '),fontweight='bold',fontsize=15)\n",
    "          s_mag,s_depth,s_chan,s_bands,s_method = ['m' + str(ev.MW), 'z' + str(int(ev.depth)) + 'km' , 'H' + chan , 'to'.join([str(int(b)) for b in band_sec]) + 's',correction_method.replace('Post','')]\n",
    "          tags = [s_chan,s_bands,s_method,s_mag+s_depth,event]\n",
    "          File = '_'.join(tags) + '.{}'.format(save_format)\n",
    "          outfile = OutFolder / s_chan / File\n",
    "          # print('{} saved to {}'.format(File,OutFolder))\n",
    "          outfile.parent.mkdir(exist_ok=True,parents=True)\n",
    "          save_tight(outfile,format=save_format,dpi=200)\n",
    "          # fig.savefig(outfile,format=save_format,dpi=400)\n",
    "      # ##### Grouped bands\n",
    "      # fig.suptitle(File.replace('_',' | ').replace('to',' to '),fontweight='bold',fontsize=15)\n",
    "      # save_tight(OutFolder / (File + '.eps' ),dpi=600)\n",
    "# --------------------------------------------\n",
    "          plt.close('all')\n",
    "  print('000'*30)\n",
    "  print(correction_method + ' ||---EV RECORDS COMPLETE---||')\n",
    "  print('000'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsta_bar = 10\n",
    "# # |||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "# # |||||| Nx2 . COHERENCE RECORDS . PLOT CODE ||||||||\n",
    "# # |||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "# # evaudit = ObsQA.io.audit_events(eventsfolder)\n",
    "# evaudit = pd.read_pickle(Path(eventsfolder) / 'event_record_audit.pkl')\n",
    "# evaudit = evaudit[evaudit.nsta>=nsta_bar]\n",
    "\n",
    "# # evsilike = ['2011.242.06.57','2010.246.16.35','2011.191.00.57','2011.236.17.46','2010.163.19.26','2010.096.22.15']\n",
    "# # evsilike = ['2011.191.00.57','2010.096.22.15']\n",
    "# # evsi = [np.where(evaudit.Event==d)[0][0] for d in evsilike]\n",
    "# # evaudit = evaudit.iloc[evsi]\n",
    "\n",
    "# # evaudit = evaudit[evaudit.MW>=7.1]\n",
    "# display(evaudit)\n",
    "# tapers = [0]\n",
    "# # methods = ['PostATACR','PostHPS']\n",
    "# # methods = ['PostATACR']\n",
    "# methods = ['PostHPS','PostATACR']\n",
    "# ysep_scl = 1.3\n",
    "# figsize = (10,10)\n",
    "# return_noise = True\n",
    "# for correction_method in methods:\n",
    "#   coh_comp = correction_method.replace('PostHPS','HPS').replace('PostATACR','ATaCR')\n",
    "#   if correction_method=='PostHPS':\n",
    "#     return_hps = True\n",
    "#     return_atacr = False\n",
    "#   else:\n",
    "#     return_hps = False\n",
    "#     return_atacr = True\n",
    "  \n",
    "#   OutFolder = Path(plotfolder)\n",
    "#   SubFolders = Path('EventRecords') / correction_method / 'coherence'\n",
    "#   OutFolder = OutFolder / SubFolders\n",
    "#   OutFolder.mkdir(parents=True,exist_ok=True)\n",
    "#   for evi,ev in enumerate(evaudit.iloc):\n",
    "#       event = ev.Event\n",
    "#       File = 'm' + str(ev.MW) + '_z' + str(ev.depth) + 'km' + '_' + event + '_' + correction_method.replace('Post','') + '_COH'\n",
    "#       title = File.replace('_',' | ').replace('z','z: ').replace('m','mag: m')\n",
    "\n",
    "#       mirror_test = mirror_audit(ev.to_frame().T,datafolder=datafolder)[0]\n",
    "#       mirror_test = np.array(mirror_test[0]) & np.array(mirror_test[1])\n",
    "#       mirror_test = np.where(mirror_test)[0]\n",
    "#       if len(mirror_test)==0:\n",
    "#         print('|| No data mirrors between sets')\n",
    "#         continue\n",
    "#       else:\n",
    "#         print('|| >>> DATASETS MIRROR POPULATION: ' + str(len(mirror_test)))\n",
    "#       if len(mirror_test)<nsta_bar:\n",
    "#         print('Insufficient mirrored data (min:' + str(nsta_bar) + ')')\n",
    "#         continue\n",
    "#       event = ev.Event\n",
    "#       stations = ev.Stations\n",
    "#       networks = ev.Networks.tolist()\n",
    "#       networks = [networks[i] for i in mirror_test]\n",
    "#       stations = [stations[i] for i in mirror_test]\n",
    "#       evdepth = ev.depth\n",
    "#       post_record = Stream()\n",
    "#       pre_record = Stream()\n",
    "#       Metrics = []\n",
    "#       print('=='*25)\n",
    "#       print('[' + str(evi) + '/' + str(len(evaudit)) + '] ' + File)\n",
    "#       print('|| [' + str(evi) + '/' + str(len(evaudit)) + '] ' + event + ' | ')\n",
    "#       print('||---Begin load')\n",
    "#       for i,(net,sta) in enumerate(zip(networks,stations)):\n",
    "#         try:\n",
    "#           M,Comp = get_metrics_comp(net,sta,MethodsFolder,event,return_hps=return_hps,return_atacr=return_atacr,events_folder='EVENTS')\n",
    "#           M['Noise'] = get_Noise(dirs['Py_DataParentFolder'],net,sta,'sta')['Noise']\n",
    "#           Metrics.append(M.copy())\n",
    "#         except:\n",
    "#           _ = stations.pop(i)\n",
    "#           _ = networks.pop(i)\n",
    "#           continue\n",
    "#         post_record += Comp[correction_method].copy()\n",
    "#         pre_record += Comp['RawZ'].copy()\n",
    "#         del Comp\n",
    "#       if len(Metrics)==0:\n",
    "#         continue\n",
    "#       evstream = post_record.copy()\n",
    "#       evstream_back = pre_record.copy()\n",
    "#       title = event\n",
    "#       sortindex = list(np.argsort([np.abs(st.stats.sac.stel*1000) for st in evstream]))\n",
    "#       sortindex.reverse()\n",
    "#       Metrics = [Metrics[s] for s in sortindex]\n",
    "#       fig, axes = plt.subplots(nrows=2, ncols=2,figsize=figsize,layout='constrained',squeeze=True,sharey='all',sharex='all')\n",
    "#       axes = axes.flatten()\n",
    "#       for ci,cmp in enumerate(['ZP','ZZ','1Z','2Z']):\n",
    "#         ax = axes[ci]\n",
    "#   # -------------\n",
    "#         if cmp=='ZP':\n",
    "#           [ax.scatter(M['Noise'].Coherence(cmp)[0],M['Noise'].Coherence(cmp)[1] + ysep*ysep_scl,c='gray',s=1) for ysep,M in enumerate(Metrics)]\n",
    "#           [ax.plot(M['Raw'].Coherence(cmp)[0],M['Raw'].Coherence(cmp)[1] + ysep*ysep_scl,c='b',linewidth=0.7) for ysep,M in enumerate(Metrics)]\n",
    "#         if cmp=='ZP':\n",
    "#           [ax.plot(M[coh_comp].Coherence(cmp)[0],M[coh_comp].Coherence(cmp)[1] + ysep*ysep_scl,c='r',linewidth=0.1) for ysep,M in enumerate(Metrics)]\n",
    "#         else:\n",
    "#           [ax.plot(M[coh_comp].Coherence(cmp)[0],M[coh_comp].Coherence(cmp)[1] + ysep*ysep_scl,c='r',linewidth=0.8) for ysep,M in enumerate(Metrics)]\n",
    "#   # -------------\n",
    "#         [ax.plot(M[coh_comp].Coherence(cmp)[0],M[coh_comp].Coherence(cmp)[1]*0 + ysep*ysep_scl,c='k',linewidth=0.1) for ysep,M in enumerate(Metrics)]\n",
    "#         fn = [fnotch(np.round(1000*abs(M['Raw'].traces.select(channel='*Z')[0].stats.sac.stel))) for M in Metrics]\n",
    "#         yticks = [ysep*ysep_scl for ysep,_ in enumerate(Metrics)]\n",
    "#         [ax.plot([f,f],[y,y+1],c='k',linewidth=0.4) for f,y in zip(fn,yticks)]\n",
    "#         [ax.text(f,y+1,'fn',horizontalalignment='center',fontsize=7,fontweight='bold') for f,y in zip(fn,yticks)]\n",
    "#         yticklabels = [str(round(1000*abs(M['Raw'].traces.select(channel='*Z')[0].stats.sac.stel))) + 'm [' + str( M['Raw'].traces.select(channel='*Z')[0].stats.network) + '] ' + str( M['Raw'].traces.select(channel='*Z')[0].stats.station) for M in Metrics]\n",
    "#         ax.set_xscale('log')\n",
    "#         f = Metrics[0][coh_comp].Coherence(cmp)[0]\n",
    "#         ax.set_xlim(f[1],f[-1])\n",
    "#         ax_title = cmp + ' Coherence'\n",
    "#         ax.set_title(ax_title,fontweight='bold')\n",
    "#         ax.set_yticks(yticks)\n",
    "#         ax.set_yticklabels(yticklabels)\n",
    "#         ax.set_ylim(yticks[0],yticks[-1]+1.3)\n",
    "#       fig.suptitle(File.replace('_',' | '),fontweight='bold',fontsize=15)\n",
    "#       save_format = 'png'\n",
    "#       # fig.suptitle(fig_title.replace('_',' | ').replace('to',' to '),fontweight='bold',fontsize=15)\n",
    "#       # File = File\n",
    "#       outfile = OutFolder / (File + '.' + save_format)\n",
    "#       save_tight(outfile,format=save_format,dpi=500)\n",
    "#       # (OutFolder / 'PNG').mkdir(parents=True,exist_ok=True)\n",
    "#       # fig.savefig(OutFolder / 'PNG' / (File + '.png'),format='png',dpi=900)\n",
    "#       plt.close('all')\n",
    "#   print('000'*30)\n",
    "#   print(correction_method + ' ||---COHERENCE RECORDS COMPLETE---||')\n",
    "#   print('000'*30)\n",
    "#         # || 26min to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ||||||||| Some old HPS Spectrogram Plot Code |||||||||\n",
    "# # ||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "# datafolder = dirs['Py_DataParentFolder']\n",
    "# # stas = ['X01','M07A','J59C','G03D','M08A'] #I only have time to print out a few. Choose these.\n",
    "# sta = None\n",
    "# # sta = \"G03A\"\n",
    "# # sta = \"M08A\"\n",
    "# # sta = \"LA34\"\n",
    "# evireq = None\n",
    "# # events_folder = 'EVENTS'\n",
    "# events_folder = 'EVENTS'\n",
    "# # sta = ['M08A']\n",
    "# #### -----\n",
    "# spectrogram_win_len = 200\n",
    "# bands = [[1,1/10],[1/10,1/30],[1/30,1/100],'Spectrogram']\n",
    "# nrows,ncols = 4,2\n",
    "# TauP = True\n",
    "# # bg_tr_color = '#cbc6f4'\n",
    "# bg_tr_color = '#3266a7'\n",
    "# Folder = Path(plotfolder) / 'MeetingFigs' / events_folder\n",
    "# Folder.mkdir(exist_ok=True)\n",
    "# (Folder / 'HPS_Spectrograms').mkdir(exist_ok=True)\n",
    "# nsta_bar = 1\n",
    "# # evaudit = ObsQA.io.audit_events(eventsfolder)\n",
    "# evaudit = pd.read_pickle(Path(eventsfolder) / 'event_record_audit.pkl')\n",
    "# # evaudit = evaudit[evaudit.nsta>=nsta_bar]\n",
    "# evsilike = ['2010.151.19.51']\n",
    "# # custom = ['YL','PL68']\n",
    "\n",
    "# evsi = [np.where(evaudit.Event==d)[0][0] for d in evsilike]\n",
    "# evaudit = evaudit.iloc[evsi]\n",
    "\n",
    "# # evaudit = evaudit[evaudit.MW>=7.1]\n",
    "# display(evaudit)\n",
    "# tapers = [3]\n",
    "# # methods = ['PostATACR','PostHPS']\n",
    "# # methods = ['PostATACR']\n",
    "# methods = ['PostHPS']\n",
    "# ysep_scl = 1.3\n",
    "# figsize = (10,10)\n",
    "# save_format = 'svg'\n",
    "# for comp_col,correction_method in enumerate(methods):\n",
    "#   coh_comp = correction_method.replace('PostHPS','HPS').replace('PostATACR','ATaCR')\n",
    "#   if correction_method=='PostHPS':\n",
    "#     return_hps = True\n",
    "#     return_atacr = False\n",
    "#   else:\n",
    "#     return_hps = False\n",
    "#     return_atacr = True\n",
    "#   for taper_mode in tapers:\n",
    "#     OutFolder = Path(plotfolder)\n",
    "#     SubFolders = Path('EventRecords') / ('Taper_' + str(taper_mode)) / correction_method / (correction_method.lower().replace('post','') + '_spectrograms')\n",
    "#     OutFolder = OutFolder / SubFolders\n",
    "#     OutFolder = Path('/Users/charlesh/Documents/Codes/OBS_Methods/NOISE/COMPS/FigureArchive/_GEN5/EventRecords/AlumniPoster/Specs')\n",
    "#     OutFolder.mkdir(parents=True,exist_ok=True)\n",
    "#     for evi,ev in enumerate(evaudit.iloc):\n",
    "#         event = ev.Event\n",
    "#         File = 'm' + str(ev.MW) + '_z' + str(ev.depth) + 'km' + '_' + event + '_' + correction_method.replace('Post','') + '_T' + str(taper_mode) + '_Spec'\n",
    "#         title = File.replace('_',' | ').replace('z','z: ').replace('m','mag: m')\n",
    "\n",
    "#         mirror_test = mirror_audit(ev.to_frame().T,datafolder=datafolder)[0]\n",
    "#         mirror_test = np.array(mirror_test[0]) & np.array(mirror_test[1])\n",
    "#         mirror_test = np.where(mirror_test)[0]\n",
    "#         if len(mirror_test)==0:\n",
    "#           print('|| No data mirrors between sets')\n",
    "#           continue\n",
    "#         else:\n",
    "#           print('|| >>> DATASETS MIRROR POPULATION: ' + str(len(mirror_test)))\n",
    "#         if len(mirror_test)<nsta_bar:\n",
    "#           print('Insufficient mirrored data (min:' + str(nsta_bar) + ')')\n",
    "#           continue\n",
    "#         event = ev.Event\n",
    "#         stations = ev.Stations\n",
    "#         networks = ev.Networks.tolist()\n",
    "#         networks = [networks[i] for i in mirror_test]\n",
    "#         stations = [stations[i] for i in mirror_test]\n",
    "# # -----------------------\n",
    "#         # networks = custom[0]\n",
    "#         # stations = custom[1]\n",
    "#         Metrics = []\n",
    "#         post_record = Stream()\n",
    "#         pre_record = Stream()\n",
    "#         for i,(net,sta) in enumerate(zip(networks,stations)):\n",
    "#           # try:\n",
    "#           M,Comp = get_metrics_comp(net,sta,datafolder,event,return_hps=return_hps,return_atacr=return_atacr,events_folder='EVENTS_Taper_' + str(taper_mode))\n",
    "#           if len(M)==0:\n",
    "#             continue\n",
    "#           M['Noise'] = get_Noise(dirs['Py_DataParentFolder'],net,sta,'sta')['Noise']\n",
    "#           # Metrics.append(M.copy())\n",
    "#           Metrics = M\n",
    "#           # except:\n",
    "#           #   _ = stations.pop(i)\n",
    "#           #   _ = networks.pop(i)\n",
    "#           #   continue\n",
    "#           post_record += Comp[correction_method].copy()\n",
    "#           pre_record += Comp['RawZ'].copy()\n",
    "#           # Metrics = Metrics[0]\n",
    "#           Station = catalog[catalog.StaName==(net + '.' + sta)].iloc[0]\n",
    "#           label = None\n",
    "#           phases=('P','S','SKS','PKiKP','SKiKS','SKSSKS',)\n",
    "#           OutPath = OutFolder\n",
    "#           fig, axes = plt.subplots(nrows=nrows, ncols=ncols,figsize=(22,12),height_ratios=[1,1,1,3],width_ratios=[1,1],layout='constrained',squeeze=False,sharey='row',sharex='row')\n",
    "#           vmin,vmax = None,None\n",
    "#           ylabel = True\n",
    "      \n",
    "#           File = Station.StaName + '.' + '.'.join(event.split('.')[0:2]) + '_' + correction_method.replace('Post','')\n",
    "#           fn = np.round(fnotch(Station.Water_Depth_m)*1000)/1000\n",
    "#           for band_row,band in enumerate(bands):\n",
    "#             for coli,prepost in enumerate(['Raw',coh_comp]):\n",
    "#               if coli==1:\n",
    "#                 lg_on = True\n",
    "#                 cbar_on = True\n",
    "#               else:\n",
    "#                 lg_on = False\n",
    "#                 cbar_on = False\n",
    "#               ax = axes[band_row,coli]\n",
    "#               label = correction_method.replace('ATaCR_HPS','ATaCR & HPS')\n",
    "#               label = prepost\n",
    "#               if band_row==0:\n",
    "#                   ttl = '' + Station.StaName + ' | Station Depth: ' + str(int(Station.Water_Depth_m)) + 'm\\n' + event + ''\n",
    "#                   fig.suptitle(ttl,fontweight='bold',y=1.06)\n",
    "#               if band!='Spectrogram':\n",
    "#                   STA_LLAZ = [Station.Latitude,Station.Longitude,Station.Water_Depth_m/1000]\n",
    "#                   event_LLAZ = [ev.ev_lla,ev.ev_lon,ev.depth]\n",
    "#                   trim = (UTCDateTime.strptime(event,format='%Y.%j.%H.%M'),UTCDateTime.strptime(event,format='%Y.%j.%H.%M')+7200)\n",
    "#                   ax = Metrics[prepost].plottrace(ax=ax,component='Z',band=band,color='k',lg=lg_on,st_llaz = STA_LLAZ,label=label,ev_llaz=event_LLAZ,phases=phases,trim=trim)\n",
    "#                   if coli==0:\n",
    "#                     band\n",
    "#                     ax.set_ylabel(str(int(1/band[0])) + 's to ' + str(int(1/band[1])) + 's',fontweight='bold')\n",
    "#               elif band=='Spectrogram':\n",
    "#                   yscale = 'log'\n",
    "#                   pc,ax = Metrics[prepost].spectrogram(plot=True,r='Z',fig=fig,ax=ax,window=spectrogram_win_len,vmin=vmin,vmax=vmax,ylabel=ylabel,cbar_on=cbar_on,yscale=yscale)\n",
    "#                   # ax.set_yscale('log')\n",
    "#                   if coli==0:\n",
    "#                       vmin,vmax = pc.get_clim()\n",
    "#                       # ylabel = False\n",
    "#                   else:\n",
    "#                     ax.set_ylabel('')\n",
    "#           save_tight(str(OutPath / (File + '.' + save_format)),format=save_format)\n",
    "#           (OutPath / 'PNG').mkdir(parents=True,exist_ok=True)\n",
    "#           save_tight(str(OutPath / 'PNG' / (File + '_lowres.png')),format='png',dpi=600)\n",
    "#           print('[' + str(evi+1) + '/' + str(len(evaudit)) + '][' + str(i+1) + '/' + str(len(stations)) + '] Save complete ' + File)\n",
    "#           plt.close('all')\n",
    "# print('****'*20)\n",
    "# print('------|||| SPECTROGRAMS COMPLETE ||||------')\n",
    "# print('****'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _next_pow2(n):\n",
    "#     return int(round(2**np.ceil(np.log2(n))))\n",
    "# def _valid_win_length_samples(win_length_samples, win_length, sampling_rate):\n",
    "#     if win_length_samples is None and win_length is None:\n",
    "#         # fully automatic window length\n",
    "#         win_length_samples = _next_pow2(120*sampling_rate)\n",
    "#     elif win_length_samples is None and win_length is not None:\n",
    "#         win_length_samples = _next_pow2(win_length*sampling_rate)\n",
    "#     elif win_length_samples is not None and win_length_samples is not None:\n",
    "#         raise ValueError(\n",
    "#             'Parameters win_length and win_length_samples are mutually '\n",
    "#             'exclusive.')\n",
    "#     elif win_length_samples is not None and win_length is None:\n",
    "#         # check win_length_samples is a power of 2\n",
    "#         win_length_samples = int(win_length_samples)\n",
    "#         if win_length_samples != _next_pow2(win_length_samples):\n",
    "#             raise ValueError(\n",
    "#                 'Parameter win_length_samples must be a power of 2.')\n",
    "#     return win_length_samples\n",
    "\n",
    "# win_length_samples = _valid_win_length_samples(win_length_samples, win_length, trace.stats.sampling_rate)\n",
    "\n",
    "# hop_length = win_length_samples // 4\n",
    "# n_fft = win_length_samples\n",
    "\n",
    "# # Compute the spectrogram amplitude and phase\n",
    "# S_full, phase = librosa.magphase(librosa.stft(x,n_fft=n_fft,hop_length=hop_length,win_length=win_length_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ||||||||||||||||||||||||||||||||||||||\n",
    "# # ||||||||||||||| STEM/LEAF PLOTS ||||||\n",
    "# # ||||||||||||||||||||||||||||||||||||||\n",
    "# cat = catalog.copy()\n",
    "# taper_mode = 0\n",
    "# return_noise = True\n",
    "# return_hps = False\n",
    "# events_folder = 'EVENTS_Taper_' + str(taper_mode)\n",
    "# figsize = (20,14)\n",
    "# coh_comps = ['ATaCR_ZZ','Noise_ZP','Raw_ZP','ATaCR_ZP','Raw_1Z','ATaCR_1Z','Raw_2Z','ATaCR_2Z']\n",
    "# nrows = len(coh_comps) + 1\n",
    "# fig, axes = plt.subplots(nrows=nrows, ncols=1,figsize=figsize,layout='constrained',squeeze=False,sharey='all',sharex='all')\n",
    "# for stai,Station in enumerate(cat.iloc):\n",
    "#   Metrics = []\n",
    "#   for evi,event in enumerate(Station.Events):\n",
    "#     notify = Station.StaName + ' ' + str(stai+1) + '/' + str(len(cat)) + ' || ' + str(evi+1) + '/' + str(len(Station.Events))\n",
    "#     try:\n",
    "#       M,Comp = get_metrics_comp(Station.Network,Station.Station,datafolder,event,return_hps=return_hps,return_noise=return_noise,events_folder=events_folder)\n",
    "#       Metrics.append(M.copy())\n",
    "#       print(notify)\n",
    "#     except:\n",
    "#       print(notify + ' | 404 Error')\n",
    "#       continue\n",
    "#   X = [stai]\n",
    "#   stats = metric_stats(Metrics)\n",
    "#   pre_stalta = stats['log_rms_stalta'][:,0]\n",
    "#   post_stalta = stats['log_rms_stalta'][:,1]\n",
    "#   ax = axes[0,0]\n",
    "#   metric_title = 'STA/LTA'\n",
    "#   for pi,p in enumerate([pre_stalta,post_stalta]):\n",
    "#     if stai==0:\n",
    "#       label = ['Pre','Post'][pi]\n",
    "#     else:\n",
    "#       label = None\n",
    "#     Y = [p.mean()]\n",
    "#     c = ['b','r'][pi]\n",
    "#     ls = ['-','--'][pi]\n",
    "#     minmax = np.atleast_2d(np.array([p.min(),p.max()])).T\n",
    "#     ax.scatter(X,Y,c=c,s=800,marker='_',label=label)\n",
    "#     ax.scatter(X,Y-p.std(),c=c,s=100,marker='_')\n",
    "#     ax.scatter(X,Y+p.std(),c=c,s=100,marker='_')\n",
    "#     # ax.errorbar(X,Y,yerr=minmax,ecolor=c,ls=ls)\n",
    "#     ax.vlines(X,minmax[0],minmax[1],colors = c,linestyles=ls,linewidth=3)\n",
    "#     # ax.errorbar(X,Y,yerr=p.std(), ecolor='r',capthick=0)\n",
    "#   ax.set_title(metric_title + '\\n Min/Max : Vertical Lines ' + ' '*10 + ' : Short Horiz. Lines' + ' '*10 + ' : Long Horiz. Lines',fontweight='bold')\n",
    "#   ax.set_ylim(0)\n",
    "#   ax.legend(ncol=2,loc='upper left')\n",
    "#   band_colors = '#901f62','#588a7d','#284ea5'\n",
    "#   bands = [[1/100,1/30],[1/30,1/10],[1/10,1]]\n",
    "#   bands = 1/np.sort(bands)\n",
    "#   for axi,coh in enumerate(coh_comps):\n",
    "#     ax = axes[axi+1,0]\n",
    "#     [ax.stem(X,np.mean((stats['coh_mu_rms_bands'][coh][:,bi])**2)**0.5,markerfmt=band_colors[bi]) for bi in range(len(bands))]\n",
    "#     ax.set_title(coh.replace('_','-') + ' Coherence RMS')\n",
    "#     if stai==0:\n",
    "#       if axi==0:\n",
    "#         [ax.stem(X,np.mean((stats['coh_mu_rms_bands'][coh][:,bi])**2)**0.5,markerfmt=band_colors[bi],label=str(bands[bi][1]) + '-' + str(bands[bi][0]) + 's',linefmt=band_colors[bi],basefmt='w') for bi in range(len(bands))]\n",
    "#     ax.legend(ncol=3,loc='upper left')\n",
    "#     ax.set_ylim(0)\n",
    "# ax = axes[-1,0]\n",
    "# xticks = [xsep for xsep,_ in enumerate(cat.iloc)]\n",
    "# xticklabels = [c.StaName for c in cat.iloc]\n",
    "# ax.set_xticks(xticks)\n",
    "# ax.set_xticklabels(xticklabels,rotation = 90)\n",
    "# folder = Path(plotfolder) / 'EventRecords' / 'Stats'\n",
    "# folder.mkdir(exist_ok=True)\n",
    "# files = 'signal_metrics_taper_' + str(taper_mode)\n",
    "# save_tight(folder / (files + '.eps' ),dpi=500)\n",
    "# # || 77min to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaudit = pd.read_pickle(Path(eventsfolder) / 'event_record_audit.pkl')\n",
    "# evaudit = evaudit[evaudit.nsta>=nsta_bar]\n",
    "# evsilike = ['2011.242.06.57','2010.246.16.35','2011.191.00.57','2011.236.17.46','2010.163.19.26','2010.096.22.15']\n",
    "# evsi = [np.where(evaudit.Event==d)[0][0] for d in evsilike]\n",
    "# evaudit = evaudit.iloc[evsi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ||||||||| Some old HPS Spectrogram Plot Code |||||||||\n",
    "# ||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "\n",
    "# # stas = ['X01','M07A','J59C','G03D','M08A'] #I only have time to print out a few. Choose these.\n",
    "# sta = None\n",
    "# # sta = \"G03A\"\n",
    "# # sta = \"M08A\"\n",
    "# # sta = \"LA34\"\n",
    "# evireq = None\n",
    "# # events_folder = 'EVENTS'\n",
    "# events_folder = 'EVENTS'\n",
    "# # sta = ['M08A']\n",
    "# #### -----\n",
    "# spectrogram_win_len = 200\n",
    "# bands = [[1/10,1/100],'Spectrogram']\n",
    "# nrows,ncols = 3,2\n",
    "# TauP = True\n",
    "# # bg_tr_color = '#cbc6f4'\n",
    "# bg_tr_color = '#3266a7'\n",
    "# Folder = Path(plotfolder) / 'MeetingFigs' / events_folder\n",
    "# Folder.mkdir(exist_ok=True)\n",
    "# (Folder / 'HPS_Spectrograms').mkdir(exist_ok=True)\n",
    "# for (Event,Station,Metrics,Comp) in OBS_Generator(catalog,parent = ATaCR_Py_DataFolder['Py_DataParentFolder'],sta=sta):\n",
    "#     label = None\n",
    "#     File = Station.StaName + '.' + '.'.join(Event.split('.')[0:2]) + '.png'\n",
    "#     OutPath = str(Folder / File)\n",
    "#     fig, axes = plt.subplots(nrows=nrows, ncols=ncols,figsize=(22,12),height_ratios=[1,1,1],width_ratios=[1,1],layout='constrained',squeeze=False,sharey='col',sharex='row')\n",
    "#     vmin,vmax = None,None\n",
    "#     ylabel = True\n",
    "#     for comp_col,correction_method in enumerate(['HPS']):\n",
    "#         fn = np.round(fnotch(Station.Water_Depth_m)*1000)/1000\n",
    "#         for band_row,band in enumerate(bands):\n",
    "#                 ax = axes[comp_col,band_row]\n",
    "#                 label = correction_method.replace('ATaCR_HPS','ATaCR & HPS')\n",
    "#                 if band_row==0:\n",
    "#                     ttl = '[' + Station.StaName + '], Station Depth: ' + str(Station.Water_Depth_m) + 'm, Notch: ' + str(fn) + 'Hz \\n' + Event + ''\n",
    "#                     fig.suptitle(ttl,fontweight='bold',y=1.06)\n",
    "#                 if band_row>0:\n",
    "#                     label=None\n",
    "#                 if band_row==0:\n",
    "#                     ax = Metrics['Raw'].plottrace(ax=ax,component='Z',band=band,color=bg_tr_color,lg=False)\n",
    "#                     ax = Metrics[correction_method].plottrace(ax=ax,component='Z',band=band,color='k',lg=True,st_llaz = Station.STA_LLAZ,ev_llaz=Station.Event_LLAZ,label=label,phases=('P','S','SKS','PKiKP','SKiKS','SKSSKS',))\n",
    "#                 elif band=='Spectrogram':\n",
    "#                     if comp_col==2:\n",
    "#                         pc,ax = Metrics[correction_method].spectrogram(plot=True,r='Z',fig=fig,ax=ax,window=spectrogram_win_len,vmin=vmin,vmax=vmax,ylabel=ylabel)\n",
    "#                         vmin,vmax = pc.get_clim()\n",
    "#                     else:\n",
    "#                         pc,ax = Metrics[correction_method].spectrogram(plot=True,r='Z',fig=fig,ax=ax,window=spectrogram_win_len,vmin=vmin,vmax=vmax,ylabel=ylabel)\n",
    "#                     if comp_col==0:\n",
    "#                         vmin,vmax = pc.get_clim()\n",
    "#                         ylabel = False\n",
    "#     save_tight(OutPath)\n",
    "#     plt.close('all')\n",
    "\n",
    "#     win_length = 200\n",
    "#     fs = Comp['PostHPS'].stats.sampling_rate\n",
    "#     (S_full, S_background, S_hps, frequencies, times) = Comp['PostHPS'].spectrograms\n",
    "#     win_length_samples = int(round(2**np.ceil(np.log2(win_length*fs))))\n",
    "#     hop_length = win_length_samples // 4\n",
    "#     n_fft = win_length_samples\n",
    "#     S_hps, phase = librosa.magphase(librosa.stft(Comp['PostHPS'].data,n_fft=n_fft,hop_length=hop_length,win_length=win_length_samples))\n",
    "#     hps_spectrograms(S_full, S_background, S_hps, frequencies, times)\n",
    "#     save_tight(str(Folder / 'HPS_Spectrograms' / File))\n",
    "#     print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ||||||||| Some old HPS Spectrogram Plot Code |||||||||\n",
    "# ||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "\n",
    "# Folder = Path(plotfolder) / 'HPS_Analysis'\n",
    "# Folder.mkdir(exist_ok=True)\n",
    "# for (Event,Station,Metrics,Comp) in OBS_Generator(catalog,ATaCR_Py_DataFolder['Py_DataParentFolder']):\n",
    "# # for i,(Event,Station,Metrics,Comp) in zip(range(1),OBS_Generator(catalog,ATaCR_Py_DataFolder['Py_DataParentFolder'])):\n",
    "#     File = Station.StaName + '.' + '.'.join(Event.split('.')[0:2]) + '.png'\n",
    "#     OutPath = str(Folder / File)\n",
    "#     print(Event)\n",
    "\n",
    "#     M = Metrics['HPS'] / Metrics['Raw']\n",
    "#     N = Metrics['Noise']\n",
    "#     R = Metrics['Raw']\n",
    "#     A = Metrics['ATaCR'] / Metrics['Raw']\n",
    "#     pairs_row1 = ['ZP','ZP','1P','2P']\n",
    "#     pairs_row2 = ['ZZ','ZZ','11','22']\n",
    "#     pairs_row23 = ['Z','Z','1','2']\n",
    "#     nrows,ncols = 4,4\n",
    "#     fig, axes = plt.subplots(nrows=nrows, ncols=ncols,figsize=(25,15),height_ratios=[1,1,1,1],width_ratios=[1,1,1,1],layout='constrained',squeeze=False)\n",
    "#     # axes = axes.reshape(nrows,ncols)\n",
    "#     plt.subplots_adjust(wspace=0.05)\n",
    "\n",
    "#     for col_i,p in enumerate(pairs_row1):\n",
    "#         row = 0\n",
    "#         ax = axes[row,col_i]\n",
    "#         [ax.axvline(f,c='k',alpha=0.3,linewidth=0.5) for f in [1/10,1/30,1/100]]\n",
    "#         x,y = N.Coherence(p)\n",
    "#         ax.scatter(x,y,s=0.1,label='Noise | Noise',c='gray')\n",
    "#         if col_i==0:\n",
    "#             x,y = A.Coherence(p)\n",
    "#             ax.plot(x,y,linewidth=0.2,label='Raw | ATaCR',c='r')\n",
    "#         else:\n",
    "#             x,y = M.Coherence(p)\n",
    "#             ax.plot(x,y,linewidth=0.2,label='Raw | HPS',c='b')\n",
    "#         ax.set_xscale('log')\n",
    "#         ax.set_xlim(x[1],x[-1])\n",
    "#         ax.set_ylim(0,1)\n",
    "#         ax.set_title('[' + p + '] ,Hz',fontweight='bold')\n",
    "#         ax.legend(loc='upper left',prop={'weight':'bold'})\n",
    "#         if col_i==0:\n",
    "#             ax.set_ylabel('Coherence')\n",
    "#         else:\n",
    "#             ax.set_yticklabels('')\n",
    "#         ax.tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "#         ax.set_xticklabels(ax.get_xticklabels(),fontweight='bold')\n",
    "\n",
    "#     for col_i,p in enumerate(pairs_row2):\n",
    "#         row = 1\n",
    "#         ax = axes[row,col_i]\n",
    "#         [ax.axvline(f,c='k',alpha=0.3,linewidth=0.5) for f in [1/10,1/30,1/100]]\n",
    "#         if col_i==0:\n",
    "#             x,y = A.Coherence(p)\n",
    "#             ax.plot(x,y,c='r',linewidth=0.2,label='Raw | ATaCR')\n",
    "#         else:\n",
    "#             x,y = M.Coherence(p)\n",
    "#             ax.plot(x,y,c='b',linewidth=0.2,label='Raw | HPS')\n",
    "#         ax.set_xscale('log')\n",
    "#         ax.set_xlim(x[1],x[-1])\n",
    "#         ax.set_ylim(0,1)\n",
    "#         ax.set_title('[' + p + ']',fontweight='bold')\n",
    "#         ax.set_xticklabels('')\n",
    "#         ax.legend(loc='upper left',prop={'weight':'bold'})\n",
    "#         if col_i==0:\n",
    "#             ax.set_ylabel('Coherence')\n",
    "#         else:\n",
    "#             ax.set_yticklabels('')\n",
    "#     sci_yl = np.floor(np.log10(np.max(np.abs([[np.min(M.traces[c][0].data),np.max(M.traces[c][0].data)] for c in ['Z','1','2']]))))\n",
    "#     yl_v = np.max(np.abs([[np.min(d.traces['Z'][0].data),np.max(d.traces['Z'][0].data)] for d in [A,M]]))\n",
    "#     yl_h = np.max([np.max(np.abs([[np.min(d.traces['1'][0].data),np.max(d.traces['1'][0].data)] for d in [A,M]])),np.max(np.abs([[np.min(d.traces['2'][0].data),np.max(d.traces['2'][0].data)] for d in [A,M]]))])\n",
    "#     for col_i,p in enumerate(pairs_row23):\n",
    "#         row = 2\n",
    "#         ax = axes[row,col_i]\n",
    "#         if col_i==0:\n",
    "#             tr = A.traces[p][0]\n",
    "#             clr = 'r'\n",
    "#             ax.set_title('ATaCR-' + p,fontweight='bold')\n",
    "#         else:\n",
    "#             tr = M.traces[p][0]\n",
    "#             clr = 'b'\n",
    "#             ax.set_title('HPS-' + p,fontweight='bold')\n",
    "#         x = R.traces[p][0].times()\n",
    "#         y = R.traces[p][0].data\n",
    "#         ax.plot(x,y,label='Raw',linewidth=0.3,c='gray')\n",
    "#         x = tr.times()\n",
    "#         y = tr.data\n",
    "#         ax.plot(x,y,label=tr.stats.location,linewidth=0.5,c=clr)\n",
    "#         ax.set_xlim(x[0],x[-1])\n",
    "#         ax.ticklabel_format(axis='both', style='sci', scilimits=(sci_yl,sci_yl+1))\n",
    "#         ax.set_xticklabels('')\n",
    "#         ax.legend(loc='upper left',prop={'weight':'bold'})\n",
    "#         if col_i<=1:\n",
    "#             ax.set_ylim(-yl_v,yl_v)\n",
    "#         else:\n",
    "#             ax.set_ylim(-yl_h,yl_h)\n",
    "#     for col_i,p in enumerate(pairs_row23):\n",
    "#         row = 3\n",
    "#         ax = axes[row,col_i]\n",
    "#         if col_i==0:\n",
    "#             f,t,s = A.spectrogram(p,plot=False,window=100,overlap=0.3)\n",
    "#         else:\n",
    "#             f,t,s = M.spectrogram(p,plot=False,window=100,overlap=0.3)\n",
    "#         # s = s - R.spectrogram(p,plot=False,window=100,yscale='log',cmap='nipy_spectral_r')[-1]\n",
    "#         s = scipy.ndimage.filters.gaussian_filter(s,sigma=0.5,mode='constant')\n",
    "#         pc = ax.pcolormesh(t,f, 10*np.log10(s), cmap = 'nipy_spectral', shading= 'auto')\n",
    "#         ax.set_yscale('log')\n",
    "#         ax.set_ylim(f[1],f[-1])\n",
    "#         if col_i==(ncols-1):\n",
    "#             # fig.colorbar(pc,ax=ax, pad=0.01, label='dB')\n",
    "#             fig.colorbar(pc,ax=ax, pad=0.01, label='dB')\n",
    "#         if col_i==0:\n",
    "#             ax.set_ylabel('Frequency Hz')\n",
    "#         else:\n",
    "#             ax.set_yticklabels('')\n",
    "#         ax.set_xticklabels(ax.get_xticklabels(),fontweight='bold')\n",
    "#         ax.set_xlabel('Time (s)',fontweight='bold')\n",
    "#         # ax.legend(loc='upper left',prop={'weight':'bold'})\n",
    "#     ttl = '[' + Station.StaName + '] ' + Event + ' '\n",
    "#     fig.suptitle(ttl,fontweight='bold',y=1.02)\n",
    "#     save_tight(OutPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================================================================================================================================================================================\n",
    "# ======================================================================================================================================================================================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Seismic_Noise_Data_Obspy_ML_NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
