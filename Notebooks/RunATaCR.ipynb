{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compliance is defined as the spectral ratio between pressure and vertical displacement data.\n",
    "# Compliance noise arises from seafloor deformation due to seafloor and water wave effects (including infragravity waves).\n",
    "# This is likely the main source of noise in vertical component OBS data.\n",
    "# This analysis therefore requires both vertical (?HZ) and pressure (?XH) data.\n",
    "\n",
    "# Tilt noise arises from OBS stations that are not perfectly leveled, and therefore the horizontal seafloor deformation leaks onto the vertical component.\n",
    "# This effect can be removed by calculating the spectral ratio between horizontal and vertical displacement data.\n",
    "# In most cases, however, the tilt direction (measured on a compass - as opposed to tilt angle, measured from the vertical axis) is unknown\n",
    "# and must be determined from the coherence between rotated horizontal components and the vertical component.\n",
    "\n",
    "# ~/opt/anaconda3/envs/Seismic_Noise_Data_Obspy_ML_NN/lib/python3.8/site-packages/obstools\n",
    "\n",
    "# CI-7D Stations Meta\n",
    "# http://service.iris.edu/irisws/fedcatalog/1/query?net=7D&starttime=2011-01-01&endtime=2017-12-31&format=text&includeoverlaps=true&nodata=404\n",
    "\n",
    "# M G and J subarrrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obstools.atacr import DayNoise, TFNoise, EventStream, StaNoise, utils\n",
    "import obstools.atacr.plotting as atplot\n",
    "from pathlib import Path\n",
    "from obspy.core import read, Stream, Trace, AttribDict, UTCDateTime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/charlesh/Documents/Codes/ATaCR')\n",
    "import ObsQA\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations, stations_set = ObsQA.io.getstalist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATaCR_Python Step-by-Step Process:\n",
    "The entire ATaCR code can be implimented to clean event data with the following seven scripts, in order:\n",
    "\n",
    "                                        1. query_fdsn_stdb\n",
    "\n",
    "                                        2. atacr_download_event\n",
    "\n",
    "                                        3. atacr_download_data\n",
    "\n",
    "                                        4. atacr_daily_spectra\n",
    "\n",
    "                                        5. atacr_clean_spectra\n",
    "\n",
    "                                        6. atacr_transfer_functions\n",
    "                                        \n",
    "                                        7. atacr_correct_event\n",
    "\n",
    "[1.] <samp><ins><< Define Station Metadata >></ins></samp> \n",
    "\n",
    "Query and save a list of stations to an stdb object in a pickle file:\n",
    "\n",
    "```\n",
    "!query_fdsn_stdb -N '{N}' -C '{C}' -S {' '.join(S)} ./Data/sta_query> ./Data/Step_1_7_StationMeta_logfile.log\n",
    "```\n",
    "You can confirm the station list with:\n",
    "\n",
    "```\n",
    "!ls_stdb ./Data/sta_query.pkl\n",
    "```\n",
    "\n",
    "[2.] <samp><ins><< Download Event Data >></ins></samp> \n",
    "\n",
    "With a general idea on the station list monitoring window, query a list of events:\n",
    "\n",
    "```\n",
    "!atacr_download_event --min-mag={Minmag} --max-mag={Maxmag} --start='{EventStart}' --end='{EventEnd}' ./Data/sta_query.pkl> ./Data/Step_2_7_EventDownload_logfile.log\n",
    "```\n",
    "\n",
    "[3.] <samp><ins><< Download Noise Data >></ins></samp> \n",
    "\n",
    "Download the time window for the generally non-transient passive data over the entire station list:\n",
    "```\n",
    "!atacr_download_data --start='{NoiseStart}' --end='{NoiseEnd}' ./Data/sta_query.pkl> ./Data/Step_3_7_NoiseDownload_logfile.log\n",
    "```\n",
    "\n",
    "[4.] <samp><ins><< Quality Control Noise Data >></ins></samp> \n",
    "\n",
    "Data quality control followed by calculating daily spectral averages for the entire array:\n",
    "```\n",
    "!atacr_daily_spectra -O --save-fig --figQC --figAverage --figCoh --start='{SpecStart}' --end='{SpecEnd}' ./Data/sta_query.pkl> ./Data/Step_4_7_QCSpectra_logfile.log\n",
    "```\n",
    "\n",
    "[5.] <samp><ins><< Calculate Noise Averages >></ins></samp> \n",
    "\n",
    "With daily averages for each station complete, produce a better and the cleanest and most continuous spectral average (ie a month long average) for each station:\n",
    "```\n",
    "!atacr_clean_spectra -O --save-fig --figQC --figAverage --figCoh --figCross --start='{SpecStart}' --end='{SpecEnd}' ./Data/sta_query.pkl> ./Data/Step_5_7_CleanSpectra_logfile.log\n",
    "```\n",
    "\n",
    "[6.] <samp><ins><< Calculate Transfer Functions >></ins></samp> \n",
    "\n",
    "With the cleanest and most complete representation of noise spectra in hand, we can now calculate transfer functions that can remove the noise contaminated between each component pair (ie, ZP-H is the tf that would remove noise from the vertical (ZP) produced by the pressure component (H)):\n",
    "```\n",
    "!atacr_transfer_functions ./Data/sta_query.pkl> ./Data/Step_6_7_CalcTFs_logfile.log\n",
    "```\n",
    "#\n",
    "#\n",
    "```java\n",
    "        Using the component noise data, six unique transfer functions will be calculated:\n",
    "\n",
    "                Respective components:\n",
    "\n",
    "                    Z: Vertical\n",
    "\n",
    "                    H1: Horizontal channel 1 (e.g. maybe E-N?)\n",
    "\n",
    "                    H2: Horizontal channel 2 (e.g. maybe N-S?)\n",
    "\n",
    "                    H: All horizontal noise rotated into into direction with the greatest the spectral density\n",
    "\n",
    "                    P: Pressure channel\n",
    "\n",
    "                The Six Transfer Functions Calculated:\n",
    "\n",
    "                    1. ZP: TF that removes pressure (P) from the vertical (Z).\n",
    "                    \n",
    "                    2. Z1: TF that removes horiz-1 (H1) from the vertical (Z).\n",
    "                    \n",
    "                    3. Z2-1: TF that removes H2 from the Z AFTER H1 was has been removed.\n",
    "                    \n",
    "                    4. ZP-21: TF that removes P from Z AFTER H1 and H2 were removed.\n",
    "                    \n",
    "                    5. ZH: TF that removes the maximum horizontal noise (found from grid-search rotations).\n",
    "                    \n",
    "                    6. ZP-H: TF that removes P from Z after H was removed.\n",
    "\n",
    "                The result is a series of filters, transfer functions, that remove all estimated noise spectra contaminating the VERTICAL component by other channels through tilt-noise, rotational-noise, and site-noise.\n",
    "```\n",
    "\n",
    "[7.] <samp><ins><< Correct Event Data with Transfer Functions >></ins></samp> \n",
    "\n",
    "Now that we have a sufficient approximation of ambient noise-spectra, whether made by tilt/rotation/site-effects/etc., that yields TFs that can remove said noise we can now test the result out on cleaning actual event (downloaded at the start) signal to see the gain in quality:\n",
    "```\n",
    "!atacr_correct_event --figRaw --figClean ./Data/sta_query.pkl> ./Data/Step_7_7_CorrectEvents_logfile.log\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some notes on the plots\n",
    "\n",
    "<samp><ins>day_corrected.png:</samp></ins> Corrected event traces using the daily spectral average of ALL data available, irrespective of any pre-event time-windows and transients in the data. These are generally not as good as the 'cleaned' spectra.\n",
    "\n",
    "<samp><ins>sta_corrected.png:</samp></ins> Corrected event traces using the 'cleaned' station spectral average that windows around (SpecAvgStart<=evtime<=SpecAvgEnd) the event time.\n",
    "\n",
    "<samp><ins>[STA].[DAY].average:</samp></ins> Station spectral average for a single day.\n",
    "\n",
    "<samp><ins>[STA].average.png:</samp></ins> Station spectral average without any 'cleaning' out the transient spectra or lame time windows.\n",
    "\n",
    "<samp><ins>coh_ph.png:</samp></ins> Daily coherence and phase as a function of rotation angle from H1. This figure can show the angle that can yield H, the maximum horizontal noise spectra possible for any rotation angle.\n",
    "\n",
    "<samp><ins>specgram_H1.H2.Z.P.png:</samp></ins> 4-C Spectrograms.\n",
    "\n",
    "<samp><ins>raw.png:</samp></ins> Raw event trace.\n",
    "\n",
    "<samp><ins>av_admittance.png:</samp></ins> Station average admittance spectra.\n",
    "\n",
    "<samp><ins>av_coherence.png:</samp></ins> Station average coherence spectra.\n",
    "\n",
    "<samp><ins>av_phase.png:</samp></ins> Station average phase spectra.\n",
    "\n",
    "<samp><ins>QC.png:</samp></ins> All 'cleaned' spectra that will be used for averaging in the TFs that surround an event time.\n",
    "\n",
    "<samp><ins>transfer_functions.png:</samp></ins> All 'cleaned' transfer functions and their average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some questions\n",
    "When looking at the cleaned spectra for a shallow OBS it seems apparent that the pressure component shows the 'notch' between the primary and secondary microsism at ~10% higher frequency than its complimentary components (H1,H2,Z). Why? I understand the notch position is controlled primarily by pressure value (P) but why this spectral hysteresis in the notch between the components?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following block does a comprehensive run of the entire ATaCR code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## for i in range(len(catalog)):\n",
    "# ##     id = np.max(np.where(catalog.iloc[i].Magnitude==np.min(catalog.iloc[i].Magnitude)))\n",
    "# ##     catalog.iat[i,np.where(catalog.columns=='events')[0][0]] = [catalog.iloc[i].events[id]]\n",
    "# ##     catalog.iat[i,np.where(catalog.columns=='Magnitude')[0][0]]= [catalog.iloc[i].Magnitude[id]]\n",
    "# ##     catalog.iat[i,np.where(catalog.columns=='DepthKM')[0][0]] = [catalog.iloc[i].DepthKM[id]]\n",
    "# ##     catalog.iat[i,np.where(catalog.columns=='Origin')[0][0]] = [catalog.iloc[i].Origin[id]]\n",
    "# ##     catalog.iat[i,np.where(catalog.columns=='Metadata')[0][0]] = [catalog.iloc[i].Metadata[id]]\n",
    "# ## catalog\n",
    "\n",
    "# eventsfolder = '/Users/charlesh/Documents/Codes/ATaCR/ATaCR_Comp/ATaCR_Python/EVENTS'\n",
    "# catalog = pd.read_pickle(eventsfolder + '/event_catalog_short_maxmag.pkl')\n",
    "# # catalog = pd.read_pickle(eventsfolder + '/event_catalog_short_minmag.pkl').sort_values(by='network')\n",
    "# display(catalog)\n",
    "\n",
    "# Minmag=6.3\n",
    "# Maxmag=6.7\n",
    "# C='?H?' #channels\n",
    "# for i in range(len(catalog)):\n",
    "#     csta = catalog.iloc[i]\n",
    "#     S = csta['station']#station\n",
    "#     N = csta['network']\n",
    "#     !query_fdsn_stdb -N '{N}' -C '{C}' -S '{S}' ./Data/sta_query> ./Data/Step_1_7_StationMeta_logfile.log\n",
    "#     for j in range(len(csta.events)):\n",
    "#         print(N + '.' + S + ' Station ' +str(i+1) + '/' + str(len(catalog)) + ' - Event ' + str(j+1) + '/' + str(len(csta.events)))\n",
    "#         ev = csta.events[j]\n",
    "#         Minmag = csta.Magnitude[0]\n",
    "\n",
    "#         NoiseStart = UTCDateTime.strptime(ev,'%Y.%j.%H.%M') - datetime.timedelta(days=30)\n",
    "#         NoiseStart = NoiseStart - datetime.timedelta(hours = NoiseStart.hour, minutes = NoiseStart.minute, seconds=NoiseStart.second) #rounds down to the nearest day\n",
    "#         NoiseEnd = UTCDateTime.strptime(ev,'%Y.%j.%H.%M')\n",
    "#         NoiseEnd = NoiseEnd - datetime.timedelta(hours = NoiseEnd.hour, minutes = NoiseEnd.minute, seconds=NoiseEnd.second) #rounds down to the nearest day\n",
    "\n",
    "#         EventStart = UTCDateTime.strptime(ev,'%Y.%j.%H.%M')\n",
    "#         EventEnd = UTCDateTime.strptime(ev,'%Y.%j.%H.%M') + datetime.timedelta(minutes=1)\n",
    "\n",
    "#         # !atacr_download_data --start='{NoiseStart}' --end='{NoiseEnd}' ./Data/sta_query.pkl> ./Data/Step_3_7_NoiseDownload_logfile.log\n",
    "#         # !atacr_download_event --min-mag={Minmag} --max-mag={Maxmag} --start='{EventStart}' --end='{EventEnd}' ./Data/sta_query.pkl> ./Data/Step_2_7_EventDownload_logfile.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## for i in range(len(catalog)):\n",
    "# ##     id = np.max(np.where(catalog.iloc[i].Magnitude==np.min(catalog.iloc[i].Magnitude)))\n",
    "# ##     catalog.iat[i,np.where(catalog.columns=='events')[0][0]] = [catalog.iloc[i].events[id]]\n",
    "# ##     catalog.iat[i,np.where(catalog.columns=='Magnitude')[0][0]]= [catalog.iloc[i].Magnitude[id]]\n",
    "# ##     catalog.iat[i,np.where(catalog.columns=='DepthKM')[0][0]] = [catalog.iloc[i].DepthKM[id]]\n",
    "# ##     catalog.iat[i,np.where(catalog.columns=='Origin')[0][0]] = [catalog.iloc[i].Origin[id]]\n",
    "# ##     catalog.iat[i,np.where(catalog.columns=='Metadata')[0][0]] = [catalog.iloc[i].Metadata[id]]\n",
    "# ## catalog\n",
    "\n",
    "# eventsfolder = '/Users/charlesh/Documents/Codes/ATaCR/ATaCR_Comp/ATaCR_Python/EVENTS'\n",
    "# catalog = pd.read_pickle(eventsfolder + '/event_catalog_short_maxmag.pkl').sort_values(by='network')\n",
    "# # catalog = pd.read_pickle(eventsfolder + '/event_catalog_short_minmag.pkl').sort_values(by='network')\n",
    "# catalog\n",
    "\n",
    "# C='?H?' #channels\n",
    "# for i in range(len(catalog)):\n",
    "#     csta = catalog.iloc[0]\n",
    "#     S = csta['station']#station\n",
    "#     N = csta['network']\n",
    "#     !query_fdsn_stdb -N '{N}' -C '{C}' -S '{S}' ./Data/sta_query> ./Data/Step_1_7_StationMeta_logfile.log\n",
    "#     for j in range(len(csta.events)):\n",
    "#         print(N + '.' + S + ' Station ' +str(i+1) + '/' + str(len(catalog)) + ' - Event ' + str(j+1) + '/' + str(len(csta.events)))\n",
    "#         ev = csta.events[j]\n",
    "#         NoiseStart = UTCDateTime.strptime(ev,'%Y.%j.%H.%M') - datetime.timedelta(days=30)\n",
    "#         NoiseStart = NoiseStart - datetime.timedelta(hours = NoiseStart.hour, minutes = NoiseStart.minute, seconds=NoiseStart.second) #rounds down to the nearest day\n",
    "#         NoiseEnd = UTCDateTime.strptime(ev,'%Y.%j.%H.%M')\n",
    "#         NoiseEnd = NoiseEnd - datetime.timedelta(hours = NoiseEnd.hour, minutes = NoiseEnd.minute, seconds=NoiseEnd.second) #rounds down to the nearest day\n",
    "#         !atacr_download_data --start='{NoiseStart}' --end='{NoiseEnd}' ./Data/sta_query.pkl> ./Data/Step_3_7_NoiseDownload_logfile.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N='XO' #network\n",
    "# C='?H?' #channels\n",
    "# stations_cull = stations_set\n",
    "# stations_cull = stations_set[stations_set['Network']==N]['Station'].to_frame()\n",
    "# stations_cull = stations_set[stations_set['Network']==N]\n",
    "# stations_cull = stations_cull.iloc[np.where(~np.isin(stations_cull['Station'],['LA30','LA33','LA34']))[0]]\n",
    "# stations_cull = stations_cull.iloc[np.where(np.isin(stations_cull['Station'],['FN14A','FS15B','G03A','G34D']))[0]]\n",
    "\n",
    "# display(stations_cull)\n",
    "# minstart = stations_cull[['Start','End']].drop_duplicates(keep='first').min()['Start']\n",
    "# maxend = stations_cull[['Start','End']].drop_duplicates(keep='first').max()['End']\n",
    "# mid_pt = minstart + datetime.timedelta(days=(maxend - minstart).days//2)\n",
    "\n",
    "# EventStart = (mid_pt - datetime.timedelta(days=200)).strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "# EventEnd = (mid_pt + datetime.timedelta(days=600)).strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "# EventStart = minstart.strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "# EventEnd = maxend.strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "# print(EventStart)\n",
    "# print(EventEnd)\n",
    "# Minmag=6.3\n",
    "# Maxmag=6.7\n",
    "\n",
    "# The scale of the event set is too large for general noise acquisition.\n",
    "# I will have to write a front end that pieces out the appropriate pre-event month long windows for each station. TLDR; A two deep (sta,event) nested for loop for noise query.\n",
    "# Will need a dataframe of available events found with each station, ie Glob the directories.\n",
    "\n",
    "# NoiseStart = EventStart\n",
    "# SpecStart = EventStart\n",
    "# NoiseEnd = EventEnd\n",
    "# SpecEnd = EventEnd\n",
    "\n",
    "\n",
    "#9/29/23 - critical event: LA34 timed out on iris event query when trying to retrieve IR. Ran again and issue repeats. I've set the query to skip this station for now as I already have 13 other events for LA34.\n",
    "# It's probably a broken header in the catalog iris uses as I know the IR data exists for this station (have it on 13 other events just fine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S= stations_cull['Station'].tolist()#station\n",
    "# !query_fdsn_stdb -N '{N}' -C '{C}' -S {','.join(S)} ./Data/sta_query> ./Data/Step_1_7_StationMeta_logfile.log\n",
    "# !atacr_download_event --min-mag={Minmag} --max-mag={Maxmag} --start='{EventStart}' --end='{EventEnd}' ./Data/sta_query.pkl> ./Data/Step_2_7_EventDownload_logfile.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Network</th>\n",
       "      <th>Latitude (deg)</th>\n",
       "      <th>Longitude (deg)</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Instrument Design</th>\n",
       "      <th>Seismometer</th>\n",
       "      <th>Environment</th>\n",
       "      <th>Pressure Gauge</th>\n",
       "      <th>Water Depth (m)</th>\n",
       "      <th>Distance from Land (km)</th>\n",
       "      <th>Distance to Plate Boundary (km)</th>\n",
       "      <th>Sediment Thickness (m)</th>\n",
       "      <th>Surface Current (m/s)</th>\n",
       "      <th>Crustal Age (Myr)</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Deployment Length (days)</th>\n",
       "      <th>Good Channels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FN07A</td>\n",
       "      <td>7D</td>\n",
       "      <td>46.855499</td>\n",
       "      <td>-124.786499</td>\n",
       "      <td>CASCADIA INITIATIVE</td>\n",
       "      <td>TRM</td>\n",
       "      <td>Trillium Compact</td>\n",
       "      <td>North Pacific</td>\n",
       "      <td>APG</td>\n",
       "      <td>154.0</td>\n",
       "      <td>46</td>\n",
       "      <td>86.731</td>\n",
       "      <td>295.000030</td>\n",
       "      <td>0.044385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-28</td>\n",
       "      <td>2012-07-20 23:59:59</td>\n",
       "      <td>359</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FN12C</td>\n",
       "      <td>7D</td>\n",
       "      <td>46.888699</td>\n",
       "      <td>-125.119003</td>\n",
       "      <td>CASCADIA INITIATIVE</td>\n",
       "      <td>TRM</td>\n",
       "      <td>Trillium Compact</td>\n",
       "      <td>North Pacific</td>\n",
       "      <td>APG</td>\n",
       "      <td>656.0</td>\n",
       "      <td>68</td>\n",
       "      <td>62.905</td>\n",
       "      <td>140.000015</td>\n",
       "      <td>0.022804</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2013-09-03</td>\n",
       "      <td>2014-06-30 23:59:59</td>\n",
       "      <td>301</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN14A</td>\n",
       "      <td>7D</td>\n",
       "      <td>47.024799</td>\n",
       "      <td>-124.964699</td>\n",
       "      <td>CASCADIA INITIATIVE</td>\n",
       "      <td>TRM</td>\n",
       "      <td>Trillium Compact</td>\n",
       "      <td>North Pacific</td>\n",
       "      <td>APG</td>\n",
       "      <td>173.0</td>\n",
       "      <td>52</td>\n",
       "      <td>77.952</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>0.026683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-31</td>\n",
       "      <td>2012-07-20 23:59:59</td>\n",
       "      <td>356</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FS15B</td>\n",
       "      <td>7D</td>\n",
       "      <td>40.492599</td>\n",
       "      <td>-124.512604</td>\n",
       "      <td>CASCADIA INITIATIVE</td>\n",
       "      <td>TRM</td>\n",
       "      <td>Trillium Compact</td>\n",
       "      <td>North Pacific</td>\n",
       "      <td>APG</td>\n",
       "      <td>52.0</td>\n",
       "      <td>12</td>\n",
       "      <td>20.088</td>\n",
       "      <td>608.000061</td>\n",
       "      <td>0.090802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-13</td>\n",
       "      <td>2013-07-03 23:59:59</td>\n",
       "      <td>294</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Station Network  Latitude (deg)  Longitude (deg)           Experiment   \n",
       "0   FN07A      7D       46.855499      -124.786499  CASCADIA INITIATIVE  \\\n",
       "2   FN12C      7D       46.888699      -125.119003  CASCADIA INITIATIVE   \n",
       "3   FN14A      7D       47.024799      -124.964699  CASCADIA INITIATIVE   \n",
       "4   FS15B      7D       40.492599      -124.512604  CASCADIA INITIATIVE   \n",
       "\n",
       "  Instrument Design       Seismometer    Environment Pressure Gauge   \n",
       "0               TRM  Trillium Compact  North Pacific            APG  \\\n",
       "2               TRM  Trillium Compact  North Pacific            APG   \n",
       "3               TRM  Trillium Compact  North Pacific            APG   \n",
       "4               TRM  Trillium Compact  North Pacific            APG   \n",
       "\n",
       "   Water Depth (m)  Distance from Land (km)  Distance to Plate Boundary (km)   \n",
       "0            154.0                       46                           86.731  \\\n",
       "2            656.0                       68                           62.905   \n",
       "3            173.0                       52                           77.952   \n",
       "4             52.0                       12                           20.088   \n",
       "\n",
       "   Sediment Thickness (m)  Surface Current (m/s)  Crustal Age (Myr)   \n",
       "0              295.000030               0.044385                NaN  \\\n",
       "2              140.000015               0.022804               9.55   \n",
       "3              187.000000               0.026683                NaN   \n",
       "4              608.000061               0.090802                NaN   \n",
       "\n",
       "       Start                 End  Deployment Length (days)  Good Channels  \n",
       "0 2011-07-28 2012-07-20 23:59:59                       359           True  \n",
       "2 2013-09-03 2014-06-30 23:59:59                       301           True  \n",
       "3 2011-07-31 2012-07-20 23:59:59                       356           True  \n",
       "4 2012-09-13 2013-07-03 23:59:59                       294           True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_cull = stations_set\n",
    "# stations_cull = stations_set[stations_set['Network']==N]['Station'].to_frame()\n",
    "# stations_cull = stations_set[stations_set['Network']==N]\n",
    "# stations_cull = stations_cull.iloc[np.where(~np.isin(stations_cull['Station'],['LA30','LA33','LA34']))[0]]\n",
    "# stations_cull = stations_cull.iloc[np.where(np.isin(stations_cull['Station'],['X05','X09']))[0]]\n",
    "stations_cull = stations_cull.iloc[[0,2,3,4]]\n",
    "if isinstance(stations_cull,pd.Series):\n",
    "    stations_cull = stations_cull.to_frame().T\n",
    "\n",
    "stations_cull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Network</th>\n",
       "      <th>Latitude (deg)</th>\n",
       "      <th>Longitude (deg)</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Instrument Design</th>\n",
       "      <th>Seismometer</th>\n",
       "      <th>Environment</th>\n",
       "      <th>Pressure Gauge</th>\n",
       "      <th>Water Depth (m)</th>\n",
       "      <th>Distance from Land (km)</th>\n",
       "      <th>Distance to Plate Boundary (km)</th>\n",
       "      <th>Sediment Thickness (m)</th>\n",
       "      <th>Surface Current (m/s)</th>\n",
       "      <th>Crustal Age (Myr)</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Deployment Length (days)</th>\n",
       "      <th>Good Channels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FN07A</td>\n",
       "      <td>7D</td>\n",
       "      <td>46.855499</td>\n",
       "      <td>-124.786499</td>\n",
       "      <td>CASCADIA INITIATIVE</td>\n",
       "      <td>TRM</td>\n",
       "      <td>Trillium Compact</td>\n",
       "      <td>North Pacific</td>\n",
       "      <td>APG</td>\n",
       "      <td>154.0</td>\n",
       "      <td>46</td>\n",
       "      <td>86.731</td>\n",
       "      <td>295.000030</td>\n",
       "      <td>0.044385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-28</td>\n",
       "      <td>2012-07-20 23:59:59</td>\n",
       "      <td>359</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FN12C</td>\n",
       "      <td>7D</td>\n",
       "      <td>46.888699</td>\n",
       "      <td>-125.119003</td>\n",
       "      <td>CASCADIA INITIATIVE</td>\n",
       "      <td>TRM</td>\n",
       "      <td>Trillium Compact</td>\n",
       "      <td>North Pacific</td>\n",
       "      <td>APG</td>\n",
       "      <td>656.0</td>\n",
       "      <td>68</td>\n",
       "      <td>62.905</td>\n",
       "      <td>140.000015</td>\n",
       "      <td>0.022804</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2013-09-03</td>\n",
       "      <td>2014-06-30 23:59:59</td>\n",
       "      <td>301</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN14A</td>\n",
       "      <td>7D</td>\n",
       "      <td>47.024799</td>\n",
       "      <td>-124.964699</td>\n",
       "      <td>CASCADIA INITIATIVE</td>\n",
       "      <td>TRM</td>\n",
       "      <td>Trillium Compact</td>\n",
       "      <td>North Pacific</td>\n",
       "      <td>APG</td>\n",
       "      <td>173.0</td>\n",
       "      <td>52</td>\n",
       "      <td>77.952</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>0.026683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-31</td>\n",
       "      <td>2012-07-20 23:59:59</td>\n",
       "      <td>356</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FS15B</td>\n",
       "      <td>7D</td>\n",
       "      <td>40.492599</td>\n",
       "      <td>-124.512604</td>\n",
       "      <td>CASCADIA INITIATIVE</td>\n",
       "      <td>TRM</td>\n",
       "      <td>Trillium Compact</td>\n",
       "      <td>North Pacific</td>\n",
       "      <td>APG</td>\n",
       "      <td>52.0</td>\n",
       "      <td>12</td>\n",
       "      <td>20.088</td>\n",
       "      <td>608.000061</td>\n",
       "      <td>0.090802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-13</td>\n",
       "      <td>2013-07-03 23:59:59</td>\n",
       "      <td>294</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Station Network  Latitude (deg)  Longitude (deg)           Experiment   \n",
       "0   FN07A      7D       46.855499      -124.786499  CASCADIA INITIATIVE  \\\n",
       "2   FN12C      7D       46.888699      -125.119003  CASCADIA INITIATIVE   \n",
       "3   FN14A      7D       47.024799      -124.964699  CASCADIA INITIATIVE   \n",
       "4   FS15B      7D       40.492599      -124.512604  CASCADIA INITIATIVE   \n",
       "\n",
       "  Instrument Design       Seismometer    Environment Pressure Gauge   \n",
       "0               TRM  Trillium Compact  North Pacific            APG  \\\n",
       "2               TRM  Trillium Compact  North Pacific            APG   \n",
       "3               TRM  Trillium Compact  North Pacific            APG   \n",
       "4               TRM  Trillium Compact  North Pacific            APG   \n",
       "\n",
       "   Water Depth (m)  Distance from Land (km)  Distance to Plate Boundary (km)   \n",
       "0            154.0                       46                           86.731  \\\n",
       "2            656.0                       68                           62.905   \n",
       "3            173.0                       52                           77.952   \n",
       "4             52.0                       12                           20.088   \n",
       "\n",
       "   Sediment Thickness (m)  Surface Current (m/s)  Crustal Age (Myr)   \n",
       "0              295.000030               0.044385                NaN  \\\n",
       "2              140.000015               0.022804               9.55   \n",
       "3              187.000000               0.026683                NaN   \n",
       "4              608.000061               0.090802                NaN   \n",
       "\n",
       "       Start                 End  Deployment Length (days)  Good Channels  \n",
       "0 2011-07-28 2012-07-20 23:59:59                       359           True  \n",
       "2 2013-09-03 2014-06-30 23:59:59                       301           True  \n",
       "3 2011-07-31 2012-07-20 23:59:59                       356           True  \n",
       "4 2012-09-13 2013-07-03 23:59:59                       294           True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4/7 - BEGIN: Quality Control Noise Data\n",
      "SPECTRA : 2011-07-28, 00:00:00 : 2014-06-30, 23:59:59\n",
      "Step 4/7 - COMPLETE: Quality Control Noise Data\n",
      "Step 5/7 - BEGIN: Spectral Average of Noise Data\n",
      "SPECTRA : 2011-07-28, 00:00:00 : 2014-06-30, 23:59:59\n",
      "/Users/charlesh/opt/anaconda3/envs/Seismic_Noise_Data_Obspy_ML_NN/lib/python3.8/site-packages/obstools/atacr/plotting.py:213: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=(6, 8))\n",
      "Step 5/7 - COMPLETE: Spectral Average of Noise Data\n",
      "Step 6/7 - BEGIN: Calculate Transfer Functions\n",
      "Step 6/7 - COMPLETE: Calculate Transfer Functions\n",
      "Step 7/7 - BEGIN: Correct Event Data\n",
      "/Users/charlesh/opt/anaconda3/envs/Seismic_Noise_Data_Obspy_ML_NN/lib/python3.8/site-packages/obstools/atacr/plotting.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=(6, 6))\n",
      "Step 7/7 - COMPLETE: Correct Event Data\n"
     ]
    }
   ],
   "source": [
    "# =============# =============# =============\n",
    "# =============# ATACR-PARAMETERS # =========\n",
    "# =============# =============# =============\n",
    "\n",
    "# N='7D' #network\n",
    "C='?H?' #channels\n",
    "display(stations_cull)\n",
    "S = stations_cull['Station'].tolist()#station\n",
    "N = stations_cull['Network'].tolist()\n",
    "# N='XO' #network\n",
    "# C='?H?' #channels\n",
    "# S= stations_set[stations_set['Network']==N]['Station'].tolist()#station\n",
    "\n",
    "# N='YO' #network\n",
    "# C='?H?' #channels\n",
    "# S= stations_set[stations_set['Network']==N]['Station'].tolist()#station\n",
    "\n",
    "\n",
    "Minmag=6.3\n",
    "Maxmag=6.7\n",
    "\n",
    "# EventStart='2012-03-01 00:00:00' #event start date\n",
    "# EventEnd='2012-03-10 00:00:00' #event end date\n",
    "# NoiseStart='2012-03-01 00:00:00' #noise start date\n",
    "# NoiseEnd='2012-03-10 00:00:00' #noise end date\n",
    "# SpecStart='2012-03-01 00:00:00' #spectral-averaging start date\n",
    "# SpecEnd='2012-03-10 00:00:00' #spectral-averaging end date\n",
    "# EventStart = (mid_pt - datetime.timedelta(days=30)).strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "# EventEnd = (mid_pt + datetime.timedelta(days=30)).strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "\n",
    "# NoiseStart = EventStart\n",
    "# SpecStart = EventStart\n",
    "# NoiseEnd = EventEnd\n",
    "# SpecEnd = EventEnd\n",
    "\n",
    "NoiseStart = stations_cull.Start.min().strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "NoiseEnd = stations_cull.End.max().strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "SpecStart = stations_cull.Start.min().strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "SpecEnd = stations_cull.End.max().strftime(\"%Y-%m-%d, %H:%M:%S\")\n",
    "\n",
    "# STEPS = [1,2,3,4,5,6,7] #Absolutely every step - Downloading adds an hour or more to the process\n",
    "STEPS = [4,5,6,7] #Everything but the download steps - About 4min for six stations.\n",
    "ClearProcessedData = False\n",
    "\n",
    "# =============# =============# =============\n",
    "# =============# =============# =============\n",
    "# =============# =============# =============\n",
    "\n",
    "if 1 not in STEPS:\n",
    "    ObsQA.io.build_staquery(stations_cull,'./Data/sta_query.pkl')\n",
    "PyATaCTPath = !pwd\n",
    "PyATaCTPath = PyATaCTPath[0]\n",
    "if ClearProcessedData:\n",
    "    !rm -rf {PyATaCTPath +  '/AVG_STA/'}\n",
    "    !rm -rf {PyATaCTPath +  '/SPECTRA/'}\n",
    "    !rm -rf {PyATaCTPath +  '/TF_STA'}\n",
    "if 1 in STEPS:\n",
    "    print('Step 1/7 - BEGIN: Station Metadata')\n",
    "    !query_fdsn_stdb -N {','.join(N)} -C '{C}' -S {','.join(S)} ./Data/sta_query> ./Data/Step_1_7_StationMeta_logfile.log\n",
    "    # !ls_stdb ./Data/sta_query.pkl\n",
    "    print('Step 1/7 - COMPLETE: Station Metadata')\n",
    "if 2 in STEPS:\n",
    "    print('Step 2/7 - BEGIN: Download Event Data')\n",
    "    print('EVENTS : ' + EventStart + ' : ' + EventEnd)\n",
    "    !atacr_download_event --min-mag={Minmag} --max-mag={Maxmag} --start='{EventStart}' --end='{EventEnd}' ./Data/sta_query.pkl> ./Data/Step_2_7_EventDownload_logfile.log\n",
    "    print('Step 2/7 - COMPLETE: Download Event Data')\n",
    "if 3 in STEPS:\n",
    "    print('Step 3/7 - BEGIN: Download Day Data')\n",
    "    print('NOISE : ' + NoiseStart + ' : ' + NoiseEnd)\n",
    "    !atacr_download_data --start='{NoiseStart}' --end='{NoiseEnd}' ./Data/sta_query.pkl> ./Data/Step_3_7_NoiseDownload_logfile.log\n",
    "    print('Step 3/7 - COMPLETE: Download Day Data')\n",
    "\n",
    "\n",
    "\n",
    "if 4 in STEPS:\n",
    "    print('Step 4/7 - BEGIN: Quality Control Noise Data')\n",
    "    print('SPECTRA : ' + SpecStart + ' : ' + SpecEnd)\n",
    "    !atacr_daily_spectra -O --figQC --figAverage --figCoh --save-fig --start='{SpecStart}' --end='{SpecEnd}' ./Data/sta_query.pkl> ./Data/Step_4_7_QCSpectra_logfile.log\n",
    "    print('Step 4/7 - COMPLETE: Quality Control Noise Data')\n",
    "if 5 in STEPS:\n",
    "    print('Step 5/7 - BEGIN: Spectral Average of Noise Data')\n",
    "    print('SPECTRA : ' + SpecStart + ' : ' + SpecEnd)\n",
    "    !atacr_clean_spectra -O --figQC --figAverage --figCoh --figCross --save-fig --start='{SpecStart}' --end='{SpecEnd}' ./Data/sta_query.pkl> ./Data/Step_5_7_CleanSpectra_logfile.log\n",
    "    print('Step 5/7 - COMPLETE: Spectral Average of Noise Data')\n",
    "if 6 in STEPS:\n",
    "    print('Step 6/7 - BEGIN: Calculate Transfer Functions')\n",
    "    !atacr_transfer_functions -O --figTF --save-fig ./Data/sta_query.pkl> ./Data/Step_6_7_CalcTFs_logfile.log\n",
    "    print('Step 6/7 - COMPLETE: Calculate Transfer Functions')\n",
    "if 7 in STEPS:\n",
    "    print('Step 7/7 - BEGIN: Correct Event Data')\n",
    "    !atacr_correct_event --figRaw --figClean --save-fig ./Data/sta_query.pkl> ./Data/Step_7_7_CorrectEvents_logfile.log\n",
    "    print('Step 7/7 - COMPLETE: Correct Event Data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sta in S:\n",
    "#     folder = './Data/' + N + '.' + sta\n",
    "#     trN1, trN2, trNZ, trNP = utils.get_data(Path(folder), UTCDateTime(Start), UTCDateTime(End))\n",
    "#     daynoise = DayNoise(trN1.merge().split()[0], trN2.merge().split()[0], trNZ.merge().split()[0], trNP.merge().split()[0])\n",
    "#     daynoise.QC_daily_spectra()\n",
    "#     # daynoise.QC_daily_spectra(fig_QC=True)\n",
    "#     daynoise.average_daily_spectra()\n",
    "#     tfnoise_day = TFNoise(daynoise)\n",
    "#     tfnoise_day.transfer_func()\n",
    "#     stanoise = StaNoise(daylist=[daynoise,daynoise])\n",
    "#     stanoise.QC_sta_spectra()\n",
    "#     stanoise.average_sta_spectra()\n",
    "#     tfnoise_sta = TFNoise(stanoise)\n",
    "#     tfnoise_sta.transfer_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daynoise = DayNoise(trN1.merge().split()[0], trN2.merge().split()[0], trNZ.merge().split()[0], trNP.merge().split()[0])\n",
    "# daynoise.QC_daily_spectra()\n",
    "# daynoise.average_daily_spectra()\n",
    "# tfnoise_day = TFNoise(daynoise)\n",
    "# tfnoise_day.transfer_func()\n",
    "# stanoise = StaNoise(daylist=[daynoise])\n",
    "# stanoise.QC_sta_spectra()\n",
    "# stanoise.average_sta_spectra()\n",
    "# tfnoise_sta = TFNoise(stanoise)\n",
    "# tfnoise_sta.transfer_func()\n",
    "# daynoise.average_daily_spectra()\n",
    "# tfnoise_day = TFNoise(daynoise)\n",
    "# tfnoise_day.transfer_func()\n",
    "# evstream.correct_data(tfnoise_day)\n",
    "# figure = atplot.fig_event_corrected(evstream, tfnoise_day.tf_list, fmin=1./150., fmax=2.)\n",
    "# figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Seismic_Noise_Data_Obspy_ML_NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
